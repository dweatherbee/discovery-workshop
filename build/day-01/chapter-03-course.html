<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui"><title>Day 1: Chapter 3</title><link rel="icon" type="image/x-icon" href="favicon.ico"><link rel="stylesheet" href="../assets/reveal.js/dist/reset.css"><link rel="stylesheet" href="../assets/reveal.js/dist/reveal.css"><link rel="stylesheet" href="../assets/theme/cockroachlabs-light.css" id="theme"><!--This CSS is generated by the Asciidoctor reveal.js converter to further integrate AsciiDoc's existing semantic with reveal.js--><style type="text/css">.reveal div.right {
  float: right
}

/* source blocks */
.reveal .listingblock.stretch > .content {
  height: 100%
}

.reveal .listingblock.stretch > .content > pre {
  height: 100%
}

.reveal .listingblock.stretch > .content > pre > code {
  height: 100%;
  max-height: 100%
}

/* auto-animate feature */
/* hide the scrollbar when auto-animating source blocks */
.reveal pre[data-auto-animate-target] {
  overflow: hidden;
}

.reveal pre[data-auto-animate-target] code {
  overflow: hidden;
}

/* add a min width to avoid horizontal shift on line numbers */
code.hljs .hljs-ln-line.hljs-ln-n {
  min-width: 1.25em;
}

/* tables */
table {
  border-collapse: collapse;
  border-spacing: 0
}

table {
  margin-bottom: 1.25em;
  border: solid 1px #dedede
}

table thead tr th, table thead tr td, table tfoot tr th, table tfoot tr td {
  padding: .5em .625em .625em;
  font-size: inherit;
  text-align: left
}

table tr th, table tr td {
  padding: .5625em .625em;
  font-size: inherit
}

table thead tr th, table tfoot tr th, table tbody tr td, table tr td, table tfoot tr td {
  display: table-cell;
  line-height: 1.6
}

td.tableblock > .content {
  margin-bottom: 1.25em
}

td.tableblock > .content > :last-child {
  margin-bottom: -1.25em
}

table.tableblock, th.tableblock, td.tableblock {
  border: 0 solid #dedede
}

table.grid-all > thead > tr > .tableblock, table.grid-all > tbody > tr > .tableblock {
  border-width: 0 1px 1px 0
}

table.grid-all > tfoot > tr > .tableblock {
  border-width: 1px 1px 0 0
}

table.grid-cols > * > tr > .tableblock {
  border-width: 0 1px 0 0
}

table.grid-rows > thead > tr > .tableblock, table.grid-rows > tbody > tr > .tableblock {
  border-width: 0 0 1px
}

table.grid-rows > tfoot > tr > .tableblock {
  border-width: 1px 0 0
}

table.grid-all > * > tr > .tableblock:last-child, table.grid-cols > * > tr > .tableblock:last-child {
  border-right-width: 0
}

table.grid-all > tbody > tr:last-child > .tableblock, table.grid-all > thead:last-child > tr > .tableblock, table.grid-rows > tbody > tr:last-child > .tableblock, table.grid-rows > thead:last-child > tr > .tableblock {
  border-bottom-width: 0
}

table.frame-all {
  border-width: 1px
}

table.frame-sides {
  border-width: 0 1px
}

table.frame-topbot, table.frame-ends {
  border-width: 1px 0
}

.reveal table th.halign-left, .reveal table td.halign-left {
  text-align: left
}

.reveal table th.halign-right, .reveal table td.halign-right {
  text-align: right
}

.reveal table th.halign-center, .reveal table td.halign-center {
  text-align: center
}

.reveal table th.valign-top, .reveal table td.valign-top {
  vertical-align: top
}

.reveal table th.valign-bottom, .reveal table td.valign-bottom {
  vertical-align: bottom
}

.reveal table th.valign-middle, .reveal table td.valign-middle {
  vertical-align: middle
}

table thead th, table tfoot th {
  font-weight: bold
}

tbody tr th {
  display: table-cell;
  line-height: 1.6
}

tbody tr th, tbody tr th p, tfoot tr th, tfoot tr th p {
  font-weight: bold
}

thead {
  display: table-header-group
}

.reveal table.grid-none th, .reveal table.grid-none td {
  border-bottom: 0 !important
}

/* kbd macro */
kbd {
  font-family: "Droid Sans Mono", "DejaVu Sans Mono", monospace;
  display: inline-block;
  color: rgba(0, 0, 0, .8);
  font-size: .65em;
  line-height: 1.45;
  background: #f7f7f7;
  border: 1px solid #ccc;
  -webkit-border-radius: 3px;
  border-radius: 3px;
  -webkit-box-shadow: 0 1px 0 rgba(0, 0, 0, .2), 0 0 0 .1em white inset;
  box-shadow: 0 1px 0 rgba(0, 0, 0, .2), 0 0 0 .1em #fff inset;
  margin: 0 .15em;
  padding: .2em .5em;
  vertical-align: middle;
  position: relative;
  top: -.1em;
  white-space: nowrap
}

.keyseq kbd:first-child {
  margin-left: 0
}

.keyseq kbd:last-child {
  margin-right: 0
}

/* callouts */
.conum[data-value] {
  display: inline-block;
  color: #fff !important;
  background: rgba(0, 0, 0, .8);
  -webkit-border-radius: 50%;
  border-radius: 50%;
  text-align: center;
  font-size: .75em;
  width: 1.67em;
  height: 1.67em;
  line-height: 1.67em;
  font-family: "Open Sans", "DejaVu Sans", sans-serif;
  font-style: normal;
  font-weight: bold
}

.conum[data-value] * {
  color: #fff !important
}

.conum[data-value] + b {
  display: none
}

.conum[data-value]:after {
  content: attr(data-value)
}

pre .conum[data-value] {
  position: relative;
  top: -.125em
}

b.conum * {
  color: inherit !important
}

.conum:not([data-value]):empty {
  display: none
}

/* Callout list */
.hdlist > table, .colist > table {
  border: 0;
  background: none
}

.hdlist > table > tbody > tr, .colist > table > tbody > tr {
  background: none
}

td.hdlist1, td.hdlist2 {
  vertical-align: top;
  padding: 0 .625em
}

td.hdlist1 {
  font-weight: bold;
  padding-bottom: 1.25em
}

/* Disabled from Asciidoctor CSS because it caused callout list to go under the
 * source listing when .stretch is applied (see #335)
 * .literalblock+.colist,.listingblock+.colist{margin-top:-.5em} */
.colist td:not([class]):first-child {
  padding: .4em .75em 0;
  line-height: 1;
  vertical-align: top
}

.colist td:not([class]):first-child img {
  max-width: none
}

.colist td:not([class]):last-child {
  padding: .25em 0
}

/* Override Asciidoctor CSS that causes issues with reveal.js features */
.reveal .hljs table {
  border: 0
}

/* Callout list rows would have a bottom border with some reveal.js themes (see #335) */
.reveal .colist > table th, .reveal .colist > table td {
  border-bottom: 0
}

/* Fixes line height with Highlight.js source listing when linenums enabled (see #331) */
.reveal .hljs table thead tr th, .reveal .hljs table tfoot tr th, .reveal .hljs table tbody tr td, .reveal .hljs table tr td, .reveal .hljs table tfoot tr td {
  line-height: inherit
}

/* Columns layout */
.columns .slide-content {
  display: flex;
}

.columns.wrap .slide-content {
  flex-wrap: wrap;
}

.columns.is-vcentered .slide-content {
  align-items: center;
}

.columns .slide-content > .column {
  display: block;
  flex-basis: 0;
  flex-grow: 1;
  flex-shrink: 1;
}

.columns .slide-content > .column > * {
  padding: .75rem;
}

/* See #353 */
.columns.wrap .slide-content > .column {
  flex-basis: auto;
}

.columns .slide-content > .column.is-full {
  flex: none;
  width: 100%;
}

.columns .slide-content > .column.is-four-fifths {
  flex: none;
  width: 80%;
}

.columns .slide-content > .column.is-three-quarters {
  flex: none;
  width: 75%;
}

.columns .slide-content > .column.is-two-thirds {
  flex: none;
  width: 66.6666%;
}

.columns .slide-content > .column.is-three-fifths {
  flex: none;
  width: 60%;
}

.columns .slide-content > .column.is-half {
  flex: none;
  width: 50%;
}

.columns .slide-content > .column.is-two-fifths {
  flex: none;
  width: 40%;
}

.columns .slide-content > .column.is-one-third {
  flex: none;
  width: 33.3333%;
}

.columns .slide-content > .column.is-one-quarter {
  flex: none;
  width: 25%;
}

.columns .slide-content > .column.is-one-fifth {
  flex: none;
  width: 20%;
}

.columns .slide-content > .column.has-text-left {
  text-align: left;
}

.columns .slide-content > .column.has-text-justified {
  text-align: justify;
}

.columns .slide-content > .column.has-text-right {
  text-align: right;
}

.columns .slide-content > .column.has-text-left {
  text-align: left;
}

.columns .slide-content > .column.has-text-justified {
  text-align: justify;
}

.columns .slide-content > .column.has-text-right {
  text-align: right;
}

.text-left {
  text-align: left !important
}

.text-right {
  text-align: right !important
}

.text-center {
  text-align: center !important
}

.text-justify {
  text-align: justify !important
}

.footnotes {
  border-top: 1px solid rgba(0, 0, 0, 0.2);
  padding: 0.5em 0 0 0;
  font-size: 0.65em;
  margin-top: 4em;
}

.byline {
  font-size:.8em
}
ul.byline {
  list-style-type: none;
}
ul.byline li + li {
  margin-top: 0.25em;
}
</style><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/all.min.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.1/css/v4-shims.min.css">
        <a href="../index.html" id="cockroachDBLogo" style="background: url(../assets/images/App_icon.svg);
                            position: absolute;
                            background-repeat: no-repeat;
                            z-index: 1000;
                            bottom: 10px;
                            left: 10px;
                            width: 50px;
                            height: 60px;">
        </a></head><body><div class="reveal"><div class="slides"><section class="title" data-state="title"><h1>Day 1</h1><h2>Chapter 3</h2></section><section id="_what_is_agentic_ai"><h2>What is Agentic AI?</h2></section>
<section><section id="_introduction_to_ai_agents"><h2>Introduction to AI Agents</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>Welcome to our introduction to AI Agents. This one-hour session serves as a foundation for the three-day workshop that follows, where we&#8217;ll focus on discovering business processes that are candidates for automation using AI agents. Today, we&#8217;ll explore what AI agents are, how they differ from traditional automation, and why they represent a significant advancement in how we approach business process automation. The concepts we cover today will be applied directly in our upcoming workshop as you identify and evaluate opportunities for implementing AI agents in your organization.</p></div></aside></div></section><section id="_why_ai_agents_matter"><h2>Why AI Agents Matter</h2><div class="slide-content"><div class="ulist"><ul><li><p>Traditional automation approaches have reached their limitations</p></li><li><p>Business demands increasingly require intelligence, not just process execution</p></li><li><p>AI agents represent a paradigm shift in how work gets accomplished</p></li><li><p>Organizations adopting AI agents realize exponential business value</p></li><li><p>Properly implemented AI agents can automate 70-90% of previously human-only tasks</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>We&#8217;re beginning our session by addressing why AI agents matter in today&#8217;s business landscape. Traditional automation approaches like robotic process automation (RPA) have been valuable but are now reaching their inherent limitations. These systems follow predefined rules without the ability to adapt to new situations or make contextual decisions.</p></div>
<div class="paragraph"><p>Today&#8217;s business challenges require more than just executing processes—they demand intelligence and adaptability. AI agents represent a fundamental shift in automation, moving from simple task execution to autonomous decision-making and outcome delivery. This shift enables organizations to automate processes that previously required human judgment.</p></div>
<div class="paragraph"><p>Organizations that have successfully implemented AI agents are seeing exponential returns on their investments. Unlike linear improvements from traditional automation, AI agents can handle increasingly complex tasks and learn from experience, delivering compounding value over time.</p></div>
<div class="paragraph"><p>Research and real-world implementations have shown that properly designed AI agents can automate 70-90% of tasks within jobs that were previously considered too complex for automation. This doesn&#8217;t necessarily mean replacing jobs, but rather augmenting human workers by handling routine aspects of their work, allowing them to focus on higher-value activities.</p></div>
<div class="paragraph"><p>Understanding AI agents is crucial for maintaining competitiveness in an increasingly AI-driven business environment. The organizations that effectively identify and implement AI agent opportunities will gain significant advantages in operational efficiency, cost reduction, and service delivery.</p></div></aside></div></section></section>
<section><section id="_from_rpa_to_ai_agents"><h2>From RPA to AI Agents</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>In this section, we&#8217;ll explore the evolution from traditional Robotic Process Automation (RPA) to modern AI agents. Understanding this transition is crucial as it demonstrates why AI agents represent such a significant advancement in business process automation. We&#8217;ll examine the key differences between these approaches and highlight why AI agents are better suited to address the complex, adaptive challenges faced by modern organizations.</p></div></aside></div></section><section id="_rpa_vs_ai_agents_key_differences"><h2>RPA vs. AI Agents: Key Differences</h2><div class="slide-content"><div class="ulist"><ul><li><p><strong>Process Execution</strong>: Rule-based automation vs. autonomous delivery</p></li><li><p><strong>Adaptability</strong>: Fixed parameters vs. contextual understanding</p></li><li><p><strong>Focus</strong>: Process-centered vs. outcome-driven</p></li><li><p><strong>Decision-making</strong>: Limited or none vs. autonomous judgment</p></li><li><p><strong>Learning</strong>: Static capabilities vs. continuous improvement</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Let&#8217;s examine the fundamental differences between traditional Robotic Process Automation (RPA) and AI agents:</p></div>
<div class="paragraph"><p>Process Execution: RPA systems excel at automating well-defined, repetitive processes through rule-based programming. They follow precise instructions without deviation. In contrast, AI agents can autonomously execute tasks by understanding the desired outcome and determining the best approach to achieve it, even when conditions change.</p></div>
<div class="paragraph"><p>Adaptability: RPA operates within fixed parameters and struggles when encountering unexpected scenarios or variations in data or processes. AI agents can understand context and adapt their approach accordingly, making them resilient to changes in the environment or inputs.</p></div>
<div class="paragraph"><p>Focus: RPA is process-centered, focusing on executing predefined steps in a workflow without regard to the ultimate business outcome. AI agents are outcome-driven, prioritizing the achievement of business objectives even if that requires adjusting their approach or making decisions not explicitly programmed.</p></div>
<div class="paragraph"><p>Decision-making: RPA systems have limited or no decision-making capabilities beyond simple conditional logic. AI agents can make autonomous judgments based on available information, weigh options, and choose the most appropriate course of action to achieve the desired outcome.</p></div>
<div class="paragraph"><p>Learning: RPA remains static unless manually reprogrammed, with no ability to improve performance based on experience. AI agents can continuously learn from interactions, feedback, and outcomes, becoming more effective and efficient over time without requiring explicit reprogramming.</p></div>
<div class="paragraph"><p>These differences highlight why AI agents represent a significant advancement over traditional automation approaches, particularly for complex, variable processes that require adaptability, decision-making, and continuous improvement.</p></div></aside></div></section><section id="_evolution_of_ai_assistance"><h2>Evolution of AI Assistance</h2><div class="slide-content"><div class="ulist"><ul><li><p><strong>AI Assistants</strong>: Chat interactions to accelerate and simplify tasks</p></li><li><p><strong>AI Agents</strong>: Pre-packaged prompts and simple workflows for repeatable tasks</p></li><li><p><strong>AI Workers</strong>: Complex workflows and reasoning for specific outcome delivery</p></li><li><p>Evolution represents increasing autonomy and complexity of handled tasks</p></li><li><p>Business value increases exponentially with sophistication of AI implementation</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The field of AI assistance has evolved through distinct stages, each representing increasing levels of autonomy and capability:</p></div>
<div class="paragraph"><p>AI Assistants represent the first wave of AI assistance most people have experienced. These systems, like basic chatbots and virtual assistants, help accelerate and simplify tasks through conversational interfaces. They respond to direct queries and commands but generally require continuous human guidance. While valuable for information retrieval and simple task execution, they lack true autonomy.</p></div>
<div class="paragraph"><p>AI Agents mark the next stage of evolution, employing pre-packaged prompts and simple workflows to complete repeatable tasks with minimal supervision. These systems can handle routine processes end-to-end, requiring human intervention only for exceptions or approvals. They represent a significant step toward automation of knowledge work.</p></div>
<div class="paragraph"><p>AI Workers represent the most advanced implementation, utilizing complex workflows and sophisticated reasoning to deliver specific outcomes with minimal human input. These systems can understand context, make judgments, and adapt their approach to achieve desired results. They can perform complete business functions previously reserved for human knowledge workers.</p></div>
<div class="paragraph"><p>This evolution represents a continuum of increasing autonomy and capability to handle complex tasks. As we move from assistants to workers, the AI takes on more responsibility and requires less human oversight and intervention.</p></div>
<div class="paragraph"><p>Importantly, business value increases exponentially as organizations implement more sophisticated AI solutions. While assistants provide valuable efficiency gains, true transformation comes from implementing autonomous AI workers that can handle complex knowledge work independently.</p></div>
<div class="paragraph"><p>Understanding where your organization currently stands in this evolution and identifying opportunities to advance to the next level will be a key focus of our upcoming workshop sessions.</p></div></aside></div></section></section>
<section><section id="_ai_knowledge_workers"><h2>AI Knowledge Workers</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>In this section, we&#8217;ll explore how AI workers function as knowledge workers, capable of performing complex cognitive tasks previously reserved for humans. Understanding the capabilities of AI knowledge workers is essential for identifying which business processes are suitable candidates for automation through AI agents.</p></div></aside></div></section><section id="_ai_workers_as_knowledge_workers"><h2>AI Workers as Knowledge Workers</h2><div class="slide-content"><div class="ulist"><ul><li><p>AI workers can perform cognitive tasks previously reserved for humans</p></li><li><p>They analyze, understand, decide, execute, and learn like human knowledge workers</p></li><li><p>AI workers combine LLMs with structured prompts, workflows, and knowledge bases</p></li><li><p>Significant advancements in AI capabilities enable complex knowledge work automation</p></li><li><p>AI workers can now handle tasks requiring judgment, analysis, and adaptation</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>AI workers represent a fundamental shift in automation capabilities, now able to perform cognitive tasks that were previously exclusive to human knowledge workers:</p></div>
<div class="paragraph"><p>AI workers mirror the cognitive processes of human knowledge workers, employing a similar workflow of analyzing information, understanding context, making decisions, executing actions, and learning from outcomes. This mirrors how human professionals approach complex tasks.</p></div>
<div class="paragraph"><p>The technical foundation of AI workers combines large language models (LLMs) with structured prompts, well-defined workflows, and access to knowledge bases. This integration creates systems capable of sophisticated reasoning and task execution beyond simple rule following.</p></div>
<div class="paragraph"><p>Recent advancements in AI capabilities, particularly in language understanding, reasoning, and context awareness, have enabled this shift. Models have progressed from simple pattern recognition to complex reasoning that can be applied to knowledge work.</p></div>
<div class="paragraph"><p>Modern AI workers can now handle tasks requiring judgment, analysis, and adaptation—activities that traditional automation could not address. They can interpret ambiguous information, weigh options based on multiple factors, and adjust their approach as circumstances change.</p></div>
<div class="paragraph"><p>This evolution has profound implications for how organizations approach automation. Processes previously considered too complex or nuanced for automation can now be candidates for AI worker implementation, expanding the automation frontier into knowledge work domains.</p></div>
<div class="paragraph"><p>As we move forward in our workshop, we&#8217;ll explore how to identify which knowledge work processes in your organization might be suitable for AI worker implementation, focusing on tasks that require analysis, understanding, decision-making, execution, and continuous improvement.</p></div></aside></div></section><section id="_core_capabilities_of_ai_knowledge_workers"><h2>Core Capabilities of AI Knowledge Workers</h2><div class="slide-content"><div class="ulist"><ul><li><p><strong>Analyze</strong>: Navigate, read, calculate, extract information</p></li><li><p><strong>Understand</strong>: Interpret, summarize, compare data and contexts</p></li><li><p><strong>Decide</strong>: Weigh options, make judgments, choose appropriate actions</p></li><li><p><strong>Execute</strong>: Click, write, post, convert, update information and systems</p></li><li><p><strong>Learn</strong>: Adapt approaches, improve performance over time</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Let&#8217;s examine the five core capabilities that enable AI workers to function effectively as knowledge workers:</p></div>
<div class="paragraph"><p>Analyze: AI workers excel at information processing, capable of navigating complex data environments, reading various document formats, calculating numerical values, and extracting relevant information from diverse sources. These analytical capabilities allow AI workers to gather and process the inputs needed for effective task completion, similar to how human workers collect and review information.</p></div>
<div class="paragraph"><p>Understand: Beyond mere data collection, AI workers can interpret information in context, summarize key points from extensive content, and compare different data points to identify patterns, relationships, and inconsistencies. This contextual understanding is crucial for meaningful automation that goes beyond simple data processing to genuine comprehension.</p></div>
<div class="paragraph"><p>Decide: AI workers can weigh multiple options based on various criteria, make judgments about the best course of action, and choose appropriate responses to situations—even when facing ambiguity or incomplete information. This decision-making capability allows AI workers to handle complex tasks that require evaluating trade-offs and selecting optimal approaches.</p></div>
<div class="paragraph"><p>Execute: After analyzing, understanding, and deciding, AI workers can take concrete actions such as clicking through interfaces, writing content, posting information, converting files between formats, and updating records in various systems. This execution capability enables AI workers to produce tangible outcomes and interact with existing digital infrastructure.</p></div>
<div class="paragraph"><p>Learn: Perhaps most importantly, AI workers can adapt their approaches based on feedback and outcomes, continuously improving their performance over time without explicit reprogramming. This learning capability ensures that AI workers become increasingly valuable assets, growing more efficient and effective through experience.</p></div>
<div class="paragraph"><p>Together, these capabilities form the foundation of AI knowledge work, enabling systems to perform complex tasks previously reserved for human professionals. When identifying processes for potential AI worker implementation, consider whether the process requires these five capabilities and to what degree the AI worker can fulfill them.</p></div></aside></div></section></section>
<section><section id="_ai_agent_architecture"><h2>AI Agent Architecture</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>In this section, we&#8217;ll explore the architecture that makes AI agents possible. Understanding the components and their relationships is essential for implementing effective AI agent solutions and evaluating potential automation candidates during our upcoming workshop.</p></div></aside></div></section><section id="_core_components_of_an_ai_agent_architecture"><h2>Core Components of an AI Agent Architecture</h2><div class="slide-content"><div class="ulist"><ul><li><p><strong>Instructions</strong>: Prompts and guidance that define the task and objectives</p></li><li><p><strong>Knowledge</strong>: Data and insights relevant to completing the task</p></li><li><p><strong>Actions</strong>: Capabilities to interact with systems and execute operations</p></li><li><p><strong>Large Language Model(s)</strong>: The reasoning engine that drives understanding and decisions</p></li><li><p><strong>Integration Layer</strong>: Connects the agent to enterprise systems and data sources</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Let&#8217;s examine the core components that comprise an effective AI agent architecture:</p></div>
<div class="paragraph"><p>Instructions form the foundation of any AI agent implementation, providing clear prompts and guidance that define what the agent should accomplish and how it should approach the task. Well-crafted instructions are critical for ensuring the agent understands its objectives, constraints, and success criteria. These can range from simple prompts to complex decision trees that guide the agent&#8217;s behavior in different scenarios.</p></div>
<div class="paragraph"><p>Knowledge represents the information resources available to the agent, including enterprise data, domain-specific insights, and contextual information relevant to completing assigned tasks. This knowledge can be provided through various mechanisms such as retrieval-augmented generation (RAG), structured databases, or direct context inclusion. The quality and relevance of this knowledge significantly impact the agent&#8217;s effectiveness.</p></div>
<div class="paragraph"><p>Actions define what the agent can actually do—its capabilities to interact with systems, manipulate data, generate content, and execute operations. These actions can include API calls to enterprise systems, browser automation for web interfaces, content generation capabilities, and communication channels. The scope of possible actions determines what tasks the agent can autonomously complete.</p></div>
<div class="paragraph"><p>Large Language Model(s) serve as the reasoning engine that powers the agent, enabling it to understand instructions, interpret knowledge, make decisions, and determine appropriate actions. The LLM&#8217;s capabilities in comprehension, reasoning, and generation directly influence the agent&#8217;s overall effectiveness and the complexity of tasks it can handle.</p></div>
<div class="paragraph"><p>Integration Layer provides the connections between the agent and enterprise systems, enabling seamless interaction with existing infrastructure, data sources, and workflows. This layer translates between the agent&#8217;s operations and the specific requirements of various systems, allowing the agent to work within the organization&#8217;s digital ecosystem.</p></div>
<div class="paragraph"><p>Understanding these components and how they interact is essential for designing effective AI agent solutions. During our workshop, we&#8217;ll explore how to evaluate and select each component based on your specific business requirements and automation objectives.</p></div></aside></div></section><section id="_ai_agent_architecture_diagram"><h2>AI Agent Architecture Diagram</h2><div class="slide-content"><div class="ulist"><ul><li><p>AI Workers interact with enterprise systems through universal API connectors or browser automation</p></li><li><p>Enterprise Knowledge Engine provides context and factual information</p></li><li><p>AI Knowledge/Actions power the agent&#8217;s capabilities to analyze, understand, decide, execute, and learn</p></li><li><p>Instructions guide the agent&#8217;s behavior and define objectives</p></li><li><p>Architecture enables controlled autonomous operation with appropriate guardrails</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The AI Agent Architecture Diagram illustrates how the various components interact to enable autonomous task completion:</p></div>
<div class="paragraph"><p>At the core of the architecture are the AI Worker capabilities we discussed earlier—the abilities to analyze, understand, decide, execute, and learn. These capabilities are enabled by the combination of large language models, structured workflows, and integration with enterprise systems.</p></div>
<div class="paragraph"><p>The Universal API Connector or Human-like Browser Mode represents the integration layer that allows AI agents to interact with enterprise systems. The API connector provides direct system integration, while browser automation enables interaction with web interfaces just as human users would. This flexibility allows agents to work with both modern API-enabled systems and legacy applications without dedicated integrations.</p></div>
<div class="paragraph"><p>The Enterprise Knowledge Engine serves as the agent&#8217;s information foundation, providing access to organizational data, documents, policies, and other knowledge resources. This component ensures the agent has the necessary context and factual information to make appropriate decisions and execute tasks correctly.</p></div>
<div class="paragraph"><p>Instructions provide the guidance and parameters that direct the agent&#8217;s behavior, defining what it should accomplish and how it should operate. These instructions can include specific prompts, workflow definitions, decision criteria, and success metrics.</p></div>
<div class="paragraph"><p>The entire architecture is designed to enable controlled autonomous operation, with appropriate guardrails ensuring the agent works within defined boundaries and according to organizational policies and standards.</p></div>
<div class="paragraph"><p>This architectural approach provides both flexibility and control—allowing organizations to implement AI agents across diverse use cases while maintaining appropriate oversight and governance. During our workshop, we&#8217;ll explore how this architecture can be applied to specific business processes in your organization.</p></div></aside></div></section></section>
<section><section id="_trusting_ai_workers"><h2>Trusting AI Workers</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>In this section, we&#8217;ll address one of the most critical aspects of implementing AI agents: establishing trust in autonomous AI systems. Understanding the requirements for building trust is essential for successful adoption and effective implementation of AI agents in your organization.</p></div></aside></div></section><section id="_requirements_for_trusting_autonomous_ai"><h2>Requirements for Trusting Autonomous AI</h2><div class="slide-content"><div class="ulist"><ul><li><p>AI needs comprehensive understanding of organizational knowledge and standards</p></li><li><p>Systems must provide visibility into AI reasoning and information sources</p></li><li><p>Organizations need control mechanisms to define and enforce behavioral boundaries</p></li><li><p>AI must respect existing permissions and security protocols</p></li><li><p>Continuous monitoring and feedback loops ensure appropriate operation</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>For AI workers to be trusted with autonomous operation, several key requirements must be satisfied:</p></div>
<div class="paragraph"><p>Comprehensive understanding of organizational knowledge and standards is essential for AI workers to operate appropriately within your business context. This means the AI must have access to relevant policies, procedures, best practices, and domain-specific information. Without this understanding, AI workers may make decisions or take actions that don&#8217;t align with organizational expectations.</p></div>
<div class="paragraph"><p>Visibility into AI reasoning and information sources provides the transparency needed for oversight and accountability. Unlike "black box" AI systems, effective AI workers should provide clear reasoning for their decisions and actions, including what information they considered and how they reached their conclusions. This visibility builds trust by making the AI&#8217;s operations understandable and auditable.</p></div>
<div class="paragraph"><p>Control mechanisms allow organizations to define and enforce behavioral boundaries for AI workers. These guardrails ensure that AI systems operate within acceptable parameters and don&#8217;t take actions that could be harmful or counter to business objectives. Control mechanisms might include approval workflows for certain actions, restrictions on system access, or explicit prohibition of specific operations.</p></div>
<div class="paragraph"><p>Respecting existing permissions and security protocols ensures that AI workers don&#8217;t circumvent established security measures or access information they shouldn&#8217;t. AI systems should operate within the same security framework as human employees, with appropriate authentication, authorization, and audit trails.</p></div>
<div class="paragraph"><p>Continuous monitoring and feedback loops provide ongoing assurance that AI workers are performing as expected and allow for correction when necessary. This includes tracking performance metrics, reviewing outcomes, and incorporating human feedback to improve future operations.</p></div>
<div class="paragraph"><p>These requirements highlight that implementing trusted AI workers isn&#8217;t just about technical capabilities—it&#8217;s equally about governance, oversight, and appropriate integration with existing organizational processes and controls. During our workshop, we&#8217;ll explore practical approaches to addressing these requirements in your specific context.</p></div></aside></div></section><section id="_building_trust_through_knowledge_and_control"><h2>Building Trust Through Knowledge and Control</h2><div class="slide-content"><div class="ulist"><ul><li><p><strong>Knowledge Integration</strong>: Connected to systems of record and sources of truth</p></li><li><p><strong>Context Access</strong>: Has the right information accessible during task execution</p></li><li><p><strong>Fact Understanding</strong>: Comprehends canonical information and organizational knowledge</p></li><li><p><strong>Boundary Definition</strong>: Clear delineation of what the AI can and cannot do</p></li><li><p><strong>Operational Transparency</strong>: Visibility into reasoning and decision processes</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Building trust in AI workers requires a balanced approach focusing on both knowledge integration and operational control:</p></div>
<div class="paragraph"><p>Knowledge Integration ensures AI workers have access to authoritative organizational information by connecting them to systems of record and sources of truth. This integration might include CRM systems, document management platforms, ERP systems, knowledge bases, and other enterprise applications. When AI has access to accurate, up-to-date information, it can make better-informed decisions and provide more reliable outputs.</p></div>
<div class="paragraph"><p>Context Access goes beyond simple system integration to ensure AI workers have the specific information needed for each task. This means implementing mechanisms that retrieve and provide relevant context at the moment it&#8217;s required, whether that&#8217;s customer history during a support interaction, policy details during a compliance review, or product specifications during a sales engagement.</p></div>
<div class="paragraph"><p>Fact Understanding enables AI workers to comprehend and correctly apply canonical information and organizational knowledge. This involves not just accessing facts but understanding their relationships, implications, and appropriate application in different scenarios. Advanced knowledge representation techniques like knowledge graphs can enhance this capability.</p></div>
<div class="paragraph"><p>Boundary Definition provides clear guardrails for AI operation by explicitly defining what the AI can and cannot do. These boundaries might include limitations on financial approval thresholds, restrictions on customer communication channels, or requirements for human approval of certain actions. Clear boundaries help prevent unexpected or inappropriate AI behaviors.</p></div>
<div class="paragraph"><p>Operational Transparency makes AI worker processes understandable and reviewable by providing visibility into reasoning and decision processes. This transparency might include explanations of why specific actions were taken, what information was considered most relevant, and how conflicting priorities were balanced. When stakeholders can see how and why the AI reached its conclusions, their trust in the system increases.</p></div>
<div class="paragraph"><p>By addressing both knowledge capabilities and control mechanisms, organizations can build AI worker implementations that earn trust through demonstrated reliability, appropriate operation, and alignment with organizational values and objectives.</p></div></aside></div></section></section>
<section><section id="_ai_workers_in_action"><h2>AI Workers in Action</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>In this section, we&#8217;ll explore concrete examples of AI workers successfully implementing automation across different business functions. These examples will help illustrate the practical applications of the concepts we&#8217;ve discussed and provide inspiration for identifying automation candidates in your own organization.</p></div></aside></div></section><section id="_example_customer_support_ai_worker"><h2>Example: Customer Support AI Worker</h2><div class="slide-content"><div class="ulist"><ul><li><p>Handles customer inquiries across multiple channels autonomously</p></li><li><p>Analyzes customer history and current issue to provide context-aware responses</p></li><li><p>Makes decisions about resolution approaches and escalation criteria</p></li><li><p>Executes actions including providing information, updating records, and initiating processes</p></li><li><p>Achieves 80% automated resolution rate with high customer satisfaction</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Let&#8217;s examine a specific example of an AI worker implementation in customer support:</p></div>
<div class="paragraph"><p>The Customer Support AI Worker handles inbound customer inquiries across multiple channels, including email, chat, and messaging platforms. Unlike simple chatbots, this AI worker can manage complete support interactions from initial contact through resolution, working autonomously for straightforward issues and collaborating with human agents for complex cases.</p></div>
<div class="paragraph"><p>This AI worker analyzes comprehensive customer context, including purchase history, previous support interactions, product usage patterns, and current account status. This deep contextual understanding enables personalized assistance that addresses the customer&#8217;s specific situation rather than providing generic responses.</p></div>
<div class="paragraph"><p>Based on its analysis, the AI worker makes informed decisions about the most appropriate resolution approach. It determines whether issues can be resolved immediately, require additional information, need escalation to specialists, or warrant proactive offers based on the customer&#8217;s situation. These decisions follow established support protocols while adapting to each unique case.</p></div>
<div class="paragraph"><p>The AI worker executes a range of actions to resolve customer issues, including providing detailed product information, troubleshooting guidance, updating customer records, processing returns or exchanges, scheduling appointments, and initiating workflows in connected systems. This action capability enables end-to-end issue resolution without human intervention in many cases.</p></div>
<div class="paragraph"><p>In real-world implementations, customer support AI workers have achieved impressive results, including 80% automated resolution rates for incoming inquiries, significant reductions in average handling time, consistent 24/7 support coverage, and high customer satisfaction ratings. The most advanced implementations learn from each interaction, continuously improving their performance based on outcomes and feedback.</p></div>
<div class="paragraph"><p>This example demonstrates how AI workers can transform customer support operations by automating routine inquiries, ensuring consistent service quality, reducing waiting times, and freeing human agents to focus on complex cases requiring specialized expertise or emotional intelligence.</p></div></aside></div></section><section id="_example_finance_ai_worker"><h2>Example: Finance AI Worker</h2><div class="slide-content"><div class="ulist"><ul><li><p>Automates invoice processing from receipt through payment approval</p></li><li><p>Validates invoice details against purchase orders, contracts, and receiving records</p></li><li><p>Identifies and resolves discrepancies according to established policies</p></li><li><p>Routes exceptions to appropriate personnel with relevant context</p></li><li><p>Reduces processing time by 70% while improving accuracy and compliance</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Let&#8217;s explore another concrete example of an AI worker implementation, this time in finance operations:</p></div>
<div class="paragraph"><p>The Finance AI Worker specializes in automating the invoice processing workflow from initial receipt through payment approval. It handles the complete process for straightforward invoices and manages the coordination of human approvals when required, maintaining end-to-end visibility throughout the workflow.</p></div>
<div class="paragraph"><p>This AI worker performs comprehensive validation of invoice details by cross-referencing information against purchase orders, contracts, receiving records, and vendor master data. It verifies line items, quantities, pricing, payment terms, tax calculations, and other critical elements to ensure accuracy before processing continues.</p></div>
<div class="paragraph"><p>When discrepancies are identified—such as price variances, quantity mismatches, or missing references—the AI worker applies established policies to determine appropriate resolution paths. It can automatically resolve minor variations within approved thresholds, initiate standardized exception processes, or compile relevant information for human review.</p></div>
<div class="paragraph"><p>For invoices requiring approval or exception handling, the AI worker routes information to the appropriate personnel based on organizational hierarchy, approval matrices, and delegation rules. Importantly, it provides complete context including highlighted discrepancies, supporting documentation, and historical patterns to facilitate efficient human decision-making.</p></div>
<div class="paragraph"><p>Organizations implementing finance AI workers have reported significant operational improvements, including 70% reductions in processing time, near-elimination of payment errors, enhanced early payment discount capture, improved vendor satisfaction, and stronger compliance with financial controls and policies.</p></div>
<div class="paragraph"><p>This example illustrates how AI workers can transform finance operations by automating routine processing, ensuring consistent application of policies, identifying potential issues proactively, and focusing human attention on exceptions and strategic decisions rather than repetitive validation tasks.</p></div></aside></div></section><section id="_example_recruitment_ai_worker"><h2>Example: Recruitment AI Worker</h2><div class="slide-content"><div class="ulist"><ul><li><p>Screens candidates against job requirements and organizational fit</p></li><li><p>Reviews resumes, applications, and assessment results</p></li><li><p>Prioritizes candidates based on customizable criteria</p></li><li><p>Schedules interviews and coordinates with hiring teams</p></li><li><p>Accelerates talent acquisition by 10x while improving quality of shortlists</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Let&#8217;s examine a third example of an AI worker implementation, focusing on recruitment and talent acquisition:</p></div>
<div class="paragraph"><p>The Recruitment AI Worker streamlines the candidate screening process by evaluating applicants against both explicit job requirements and more nuanced organizational fit criteria. It processes applications as they arrive, ensuring consistent evaluation standards and rapid response times regardless of volume fluctuations.</p></div>
<div class="paragraph"><p>This AI worker conducts comprehensive review of candidate materials including resumes, application forms, assessment results, portfolio samples, and public professional profiles. It extracts relevant qualifications, experiences, and indicators of potential success, creating standardized candidate profiles that facilitate objective comparison.</p></div>
<div class="paragraph"><p>Based on configurable evaluation frameworks, the AI worker prioritizes candidates according to multiple dimensions including technical qualifications, relevant experience, growth potential, diversity considerations, and alignment with organizational values. These prioritization models can be customized for different roles and adjusted based on hiring outcomes to improve future recommendations.</p></div>
<div class="paragraph"><p>For candidates meeting threshold criteria, the AI worker manages the interview scheduling process, coordinating availability among candidates and hiring team members, sending calendar invitations, providing preparation materials, and handling rescheduling needs. This automation eliminates the administrative burden that often delays the hiring process.</p></div>
<div class="paragraph"><p>Organizations implementing recruitment AI workers have achieved remarkable efficiency gains, including 10x faster candidate processing, significant improvements in shortlist quality as measured by hiring manager satisfaction, reduced time-to-hire metrics, and more consistent candidate experiences regardless of application volume.</p></div>
<div class="paragraph"><p>This example demonstrates how AI workers can transform recruitment operations by eliminating processing bottlenecks, ensuring consistent and objective evaluation, reducing administrative overhead, and enabling recruiting teams to focus on high-value activities like candidate engagement and hiring manager partnerships.</p></div></aside></div></section></section>
<section><section id="_identifying_ai_worker_opportunities"><h2>Identifying AI Worker Opportunities</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>This section prepares participants for the upcoming three-day workshop by introducing frameworks for identifying business processes that are strong candidates for AI worker implementation. Understanding these evaluation criteria will enable more effective discovery and prioritization during the workshop activities.</p></div></aside></div></section><section id="_process_decomposition_for_ai_implementation"><h2>Process Decomposition for AI Implementation</h2><div class="slide-content"><div class="ulist"><ul><li><p>Break business processes into atomic components before applying AI</p></li><li><p>Identify pattern-recognition tasks ideal for AI automation</p></li><li><p>Recognize contextual reasoning tasks suitable for hybrid AI-human approaches</p></li><li><p>Reserve creative/ethical judgment tasks for human-led work with AI support</p></li><li><p>Most successful implementations automate 70-90% of tasks within jobs, not entire roles</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>One of the most critical success factors for AI worker implementation is effective process decomposition:</p></div>
<div class="paragraph"><p>Breaking business processes into atomic components before applying AI allows organizations to identify precisely where AI can add the most value. This granular approach avoids the common pitfall of trying to automate entire roles or complex processes all at once. Instead, it focuses on understanding the specific tasks and decisions that comprise each process.</p></div>
<div class="paragraph"><p>Through decomposition, organizations can identify pattern-recognition tasks that are ideal candidates for AI automation. These tasks involve analyzing data, recognizing trends, categorizing information, or making predictions based on historical patterns—all areas where AI excels. Examples include document classification, anomaly detection, sentiment analysis, and trend identification.</p></div>
<div class="paragraph"><p>The decomposition also reveals contextual reasoning tasks that benefit from a hybrid AI-human approach. These tasks require understanding broader context, applying judgment within defined parameters, or making decisions based on multiple factors. In these scenarios, AI can perform initial analysis and provide recommendations, with humans making final decisions or handling edge cases.</p></div>
<div class="paragraph"><p>Finally, process decomposition highlights creative and ethical judgment tasks that should remain primarily human-led, though potentially with AI support. These tasks involve novel problem-solving, ethical considerations, emotional intelligence, or strategic thinking where human judgment remains essential. AI can assist by providing information, generating options, or handling routine aspects of these tasks.</p></div>
<div class="paragraph"><p>The most successful AI implementations focus on automating the 70-90% of tasks within jobs that follow predictable patterns, rather than attempting to replace entire roles. This approach maximizes impact while acknowledging the continuing value of human creativity, judgment, and interpersonal skills.</p></div>
<div class="paragraph"><p>During our upcoming workshop, we&#8217;ll apply this decomposition framework to your specific business processes, identifying the components most suitable for AI worker implementation and designing approaches that effectively combine AI and human capabilities.</p></div></aside></div></section><section id="_evaluating_processes_for_ai_worker_potential"><h2>Evaluating Processes for AI Worker Potential</h2><div class="slide-content"><div class="ulist"><ul><li><p>Assess process volume, frequency, and business impact</p></li><li><p>Evaluate current process stability, standardization, and documentation</p></li><li><p>Consider data availability, quality, and accessibility</p></li><li><p>Identify potential integration points with existing systems</p></li><li><p>Analyze return on investment including both direct and indirect benefits</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>When evaluating business processes for AI worker implementation potential, several key factors should be considered:</p></div>
<div class="paragraph"><p>Process volume, frequency, and business impact help determine whether automation will deliver meaningful results. High-volume, frequently performed processes with significant business impact typically offer the greatest return on AI investment. For example, processes handling thousands of transactions daily that directly affect customer experience or financial outcomes are strong candidates.</p></div>
<div class="paragraph"><p>Current process stability, standardization, and documentation indicate how ready a process is for AI implementation. Well-defined, stable processes with clear documentation are easier to automate effectively. Processes with frequent changes, inconsistent execution, or poor documentation may require standardization before AI implementation.</p></div>
<div class="paragraph"><p>Data availability, quality, and accessibility are critical considerations since AI workers depend on information to function effectively. Processes with structured, digitized data that&#8217;s readily accessible typically offer smoother implementation paths. Data quality issues, paper-based information, or siloed systems may require additional preparation work.</p></div>
<div class="paragraph"><p>Integration points with existing systems determine how smoothly an AI worker can operate within your technological ecosystem. Processes that interact with systems offering modern APIs, structured data formats, or browser-based interfaces are generally easier to automate. Legacy systems with limited integration capabilities may present additional challenges.</p></div>
<div class="paragraph"><p>Return on investment analysis should consider both direct benefits (cost savings, throughput improvements, error reduction) and indirect benefits (improved employee experience, enhanced customer satisfaction, better compliance). Comprehensive ROI evaluation helps prioritize implementation efforts for maximum organizational impact.</p></div>
<div class="paragraph"><p>During our workshop, we&#8217;ll use these evaluation criteria to systematically assess potential automation candidates in your organization, developing a prioritized roadmap based on implementation feasibility and expected business impact.</p></div></aside></div></section></section>
<section><section id="_human_ai_collaboration_models"><h2>Human-AI Collaboration Models</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>This final section explores the future of work through the lens of human-AI collaboration, preparing participants to envision and design effective partnership models during the upcoming workshop.</p></div></aside></div></section><section id="_designing_effective_human_ai_teaming_models"><h2>Designing Effective Human-AI Teaming Models</h2><div class="slide-content"><div class="ulist"><ul><li><p>Focus on symbiotic workflows where humans and AI complement each other</p></li><li><p>Leverage AI for data processing, pattern recognition, and routine decision-making</p></li><li><p>Position humans for complex judgment, creativity, and emotional intelligence</p></li><li><p>Implement continuous learning loops where AI improves through human feedback</p></li><li><p>Design workflows that would be impossible with either humans or AI alone</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The most successful AI implementations focus not on replacement but on creating effective human-AI partnerships:</p></div>
<div class="paragraph"><p>Symbiotic workflows represent the ideal state of human-AI collaboration, where each partner contributes their unique strengths to achieve outcomes neither could accomplish alone. This approach moves beyond simplistic automation to reimagine processes that leverage the complementary capabilities of both humans and AI systems.</p></div>
<div class="paragraph"><p>In effective teaming models, AI handles data-intensive tasks where it excels—processing large volumes of information, identifying patterns across diverse datasets, performing consistent analysis, and making routine decisions based on established criteria. This frees human capacity for higher-value activities while ensuring consistent handling of information-intensive tasks.</p></div>
<div class="paragraph"><p>Humans remain essential for complex judgment requiring nuanced understanding, ethical considerations, novel problem-solving, and emotional intelligence. These uniquely human capabilities ensure appropriate handling of edge cases, ethical dilemmas, innovation opportunities, and sensitive interactions where context and values matter deeply.</p></div>
<div class="paragraph"><p>Continuous learning loops create ever-improving systems by capturing human feedback and incorporating it into AI operation. When humans review AI outputs, provide corrections, or handle exceptions, these interactions become learning opportunities that enhance future AI performance. Over time, the AI requires fewer interventions as it adapts to organizational preferences and edge cases.</p></div>
<div class="paragraph"><p>The most advanced implementations create workflows that would be impossible with either humans or AI working independently. For example, AI might analyze thousands of customer interactions to identify emerging issues and present them to human experts who can quickly develop solutions. Neither partner could effectively perform the complete workflow alone—the AI couldn&#8217;t develop the creative solutions, while humans couldn&#8217;t process the volume of interactions to identify patterns.</p></div>
<div class="paragraph"><p>During our workshop, we&#8217;ll explore how to design these symbiotic teaming models for your specific business context, creating collaboration approaches that maximize the strengths of both human employees and AI workers.</p></div></aside></div></section><section id="_transforming_into_an_ai_first_business"><h2>Transforming into an AI-First Business</h2><div class="slide-content"><div class="ulist"><ul><li><p>Implement ruthless process decomposition before applying AI</p></li><li><p>Position data infrastructure as the organizational foundation</p></li><li><p>Design symbiotic human-AI workflows that leverage complementary strengths</p></li><li><p>Focus on augmenting human capabilities rather than replacing roles</p></li><li><p>Create continuous feedback loops that improve AI performance over time</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>As we conclude our introduction and prepare for the detailed work of our upcoming workshop, let&#8217;s consider what it means to transform into a truly AI-first business:</p></div>
<div class="paragraph"><p>Ruthless process decomposition serves as the foundation for effective AI implementation. Before deploying any AI solution, successful organizations break every business process into its atomic components, identifying which specific tasks are suitable for AI automation, which benefit from hybrid approaches, and which should remain primarily human-led. This granular understanding prevents the common pitfall of attempting to automate entire jobs rather than focusing on the 70-90% of tasks within those jobs that follow predictable patterns.</p></div>
<div class="paragraph"><p>In AI-first organizations, data infrastructure becomes the organizational foundation rather than merely supporting existing structures. These companies architect their entire operations around their data assets, with every decision—from hiring to product development—evaluated based on how it will improve data positioning. This approach recognizes that the quality, accessibility, and organization of data directly determine the effectiveness of AI implementations.</p></div>
<div class="paragraph"><p>Symbiotic human-AI workflows represent the operational model of AI-first businesses. Rather than viewing AI merely as a cost-reduction tool, these organizations create collaborative processes that would be impossible with either humans or AI working independently. These workflows leverage the complementary strengths of both partners—AI&#8217;s ability to process vast amounts of information and identify patterns, combined with human creativity, judgment, and emotional intelligence.</p></div>
<div class="paragraph"><p>The focus on augmenting human capabilities rather than replacing roles distinguishes truly transformative AI implementations. By automating routine aspects of jobs, AI-first organizations enable their employees to focus on higher-value activities that leverage uniquely human strengths. This approach not only improves operational efficiency but also enhances employee satisfaction and engagement by eliminating tedious tasks.</p></div>
<div class="paragraph"><p>Finally, AI-first organizations implement continuous feedback loops that improve AI performance over time. They create systems where humans teach AI through their responses to recommendations, corrections to outputs, and handling of exceptions. This creates a virtuous cycle where the AI system requires fewer interventions over time as it adapts to organizational needs and preferences.</p></div>
<div class="paragraph"><p>During our upcoming workshop, we&#8217;ll explore how to apply these principles to your specific business context, creating a roadmap for transforming into an AI-first organization that leverages the full potential of human-AI collaboration.</p></div></aside></div></section></section>
<section><section id="_summary"><h2>Summary</h2></section><section id="_key_takeaways"><h2>Key Takeaways</h2><div class="slide-content"><div class="ulist"><ul><li><p>AI agents represent a significant advancement over rule-based automation</p></li><li><p>AI workers function as knowledge workers with analyze-understand-decide-execute-learn capabilities</p></li><li><p>Effective implementation requires understanding AI architecture components and their relationships</p></li><li><p>Trust in autonomous AI depends on knowledge integration and appropriate control mechanisms</p></li><li><p>Human-AI teaming models create outcomes impossible for either alone</p></li><li><p>Process decomposition is critical for identifying suitable automation candidates</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>As we conclude our introduction to AI agents, let&#8217;s recap the key concepts we&#8217;ve explored today:</p></div>
<div class="paragraph"><p>AI agents represent a fundamental advancement beyond traditional rule-based automation approaches like RPA. Unlike their predecessors, AI agents can adapt to changing conditions, make autonomous decisions, and focus on outcomes rather than just processes. This shift enables automation of complex knowledge work previously considered too nuanced for traditional approaches.</p></div>
<div class="paragraph"><p>AI workers function as true knowledge workers, with capabilities that mirror human cognitive processes: analyzing information, understanding context, making decisions, executing actions, and learning from experience. This comprehensive capability set allows AI workers to handle sophisticated tasks requiring judgment and adaptation.</p></div>
<div class="paragraph"><p>Implementing effective AI workers requires understanding the core architectural components—instructions, knowledge, actions, language models, and integration layers—and how they work together to enable autonomous task completion. This architectural understanding is essential for designing solutions that deliver on the promise of AI-powered automation.</p></div>
<div class="paragraph"><p>Building trust in autonomous AI systems depends on both comprehensive knowledge integration and appropriate control mechanisms. AI workers must have access to organizational information and context while operating within clearly defined boundaries that ensure alignment with business objectives and values.</p></div>
<div class="paragraph"><p>The most successful implementations focus not on replacing humans but on creating effective human-AI teaming models that leverage the complementary strengths of both partners. These symbiotic workflows enable outcomes that would be impossible for either humans or</p></div></aside></div></section></section>
<section><section id="_quiz_time"><h2>Quiz Time!</h2><div class="slide-content"><aside class="notes"><div class="paragraph"><p>Now let&#8217;s test our understanding of the key concepts we&#8217;ve covered in today&#8217;s session with a brief quiz. This will help reinforce the important points before we move into our three-day workshop on discovering business processes for AI agent automation.</p></div></aside></div></section><section id="_question_1"><h2>Question 1</h2><div class="slide-content"><div class="paragraph"><p>What is the primary difference between RPA and AI agents?</p></div>
<div class="ulist"><ul><li><p>A) RPA is more expensive to implement than AI agents</p></li><li><p>B) RPA follows rule-based automation while AI agents can adapt and make autonomous decisions</p></li><li><p>C) AI agents can only work with structured data</p></li><li><p>D) RPA is faster at executing tasks than AI agents</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is B. RPA follows rule-based automation while AI agents can adapt and make autonomous decisions. This represents a fundamental difference in capability - RPA executes predefined processes without deviation, while AI agents can understand context, adapt to changing conditions, and autonomously determine the best approach to achieve desired outcomes.</p></div></aside></div></section><section id="_question_2"><h2>Question 2</h2><div class="slide-content"><div class="paragraph"><p>Which of the following represents the most advanced implementation of AI assistance?</p></div>
<div class="ulist"><ul><li><p>A) AI Assistants</p></li><li><p>B) AI Agents</p></li><li><p>C) AI Workers</p></li><li><p>D) AI Chatbots</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is C. AI Workers represent the most advanced implementation, utilizing complex workflows and sophisticated reasoning to deliver specific outcomes with minimal human input. They can understand context, make judgments, and adapt their approach to achieve desired results, performing complete business functions previously reserved for human knowledge workers.</p></div></aside></div></section><section id="_question_3"><h2>Question 3</h2><div class="slide-content"><div class="paragraph"><p>What are the five core capabilities of AI knowledge workers?</p></div>
<div class="ulist"><ul><li><p>A) Plan, Program, Process, Predict, Perform</p></li><li><p>B) Collect, Compute, Create, Communicate, Complete</p></li><li><p>C) Analyze, Understand, Decide, Execute, Learn</p></li><li><p>D) Search, Sort, Summarize, Suggest, Solve</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is C. The five core capabilities of AI knowledge workers are: Analyze (navigate, read, calculate, extract information), Understand (interpret, summarize, compare data and contexts), Decide (weigh options, make judgments, choose appropriate actions), Execute (click, write, post, convert, update information and systems), and Learn (adapt approaches, improve performance over time).</p></div></aside></div></section><section id="_question_4"><h2>Question 4</h2><div class="slide-content"><div class="paragraph"><p>Which of these is NOT a core component of an AI Agent Architecture?</p></div>
<div class="ulist"><ul><li><p>A) Instructions</p></li><li><p>B) Knowledge</p></li><li><p>C) Social intelligence</p></li><li><p>D) Large Language Model(s)</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is C. Social intelligence is not listed as one of the core components of an AI Agent Architecture. The core components we discussed are: Instructions (prompts and guidance), Knowledge (relevant data and insights), Actions (capabilities to interact with systems), Large Language Model(s) (the reasoning engine), and Integration Layer (connections to enterprise systems).</p></div></aside></div></section><section id="_question_5"><h2>Question 5</h2><div class="slide-content"><div class="paragraph"><p>What is a key requirement for trusting autonomous AI in business environments?</p></div>
<div class="ulist"><ul><li><p>A) AI must always operate completely independently without human oversight</p></li><li><p>B) AI needs comprehensive understanding of organizational knowledge and standards</p></li><li><p>C) AI should prioritize speed over accuracy</p></li><li><p>D) AI must be developed in-house rather than using vendor solutions</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is B. AI needs comprehensive understanding of organizational knowledge and standards to be trusted with autonomous operation. This ensures the AI operates appropriately within the business context, following relevant policies, procedures, and best practices. Other requirements include visibility into AI reasoning, control mechanisms, respecting existing permissions, and continuous monitoring.</p></div></aside></div></section><section id="_question_6"><h2>Question 6</h2><div class="slide-content"><div class="paragraph"><p>What percentage of tasks within jobs can typically be automated with properly implemented AI agents?</p></div>
<div class="ulist"><ul><li><p>A) 20-30%</p></li><li><p>B) 40-50%</p></li><li><p>C) 70-90%</p></li><li><p>D) 100%</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is C. Research and real-world implementations have shown that properly designed AI agents can automate 70-90% of tasks within jobs that were previously considered too complex for automation. This doesn&#8217;t necessarily mean replacing jobs entirely, but rather augmenting human workers by handling routine aspects of their work.</p></div></aside></div></section><section id="_question_7"><h2>Question 7</h2><div class="slide-content"><div class="paragraph"><p>What is the recommended approach for identifying AI worker opportunities in business processes?</p></div>
<div class="ulist"><ul><li><p>A) Automate entire departments at once</p></li><li><p>B) Focus only on customer-facing processes</p></li><li><p>C) Break business processes into atomic components before applying AI</p></li><li><p>D) Implement AI only in processes that are already fully digital</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is C. Breaking business processes into atomic components before applying AI is the recommended approach. This process decomposition allows organizations to identify precisely where AI can add the most value, focusing on specific tasks and decisions rather than trying to automate entire roles or complex processes all at once.</p></div></aside></div></section><section id="_question_8"><h2>Question 8</h2><div class="slide-content"><div class="paragraph"><p>In effective human-AI teaming models, what role should humans typically play?</p></div>
<div class="ulist"><ul><li><p>A) Humans should only supervise AI decisions</p></li><li><p>B) Humans should focus on complex judgment, creativity, and emotional intelligence</p></li><li><p>C) Humans should primarily handle data entry and routine tasks</p></li><li><p>D) Humans should be removed from all processes where AI is implemented</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>The correct answer is B. In effective human-AI teaming models, humans should focus on complex judgment requiring nuanced understanding, ethical considerations, novel problem-solving, and emotional intelligence. These uniquely human capabilities ensure appropriate handling of edge cases, ethical dilemmas, innovation opportunities, and sensitive interactions where context and values matter deeply.</p></div></aside></div></section></section>
<section><section id="_thank_you"><h2>Thank You!</h2></section><section id="_next_steps"><h2>Next Steps</h2><div class="slide-content"><div class="ulist"><ul><li><p>Tomorrow we begin our three-day workshop on discovering business processes for AI agent automation</p></li><li><p>Please come prepared with specific processes from your department to analyze</p></li><li><p>We&#8217;ll apply the frameworks and concepts from today to identify high-value automation opportunities</p></li><li><p>Questions? Contact the workshop facilitator at [<a href="mailto:facilitator@example.com">facilitator@example.com</a>]</p></li></ul></div>
<aside class="notes"><div class="paragraph"><p>Thank you for your participation in today&#8217;s introduction to AI agents. This session has laid the groundwork for our upcoming three-day workshop, where we&#8217;ll focus on discovering business processes in your organization that are candidates for automation using AI agents.</p></div>
<div class="paragraph"><p>Please come prepared tomorrow with specific processes from your department that you&#8217;d like to analyze. We&#8217;ll apply the frameworks and concepts we&#8217;ve discussed today to identify high-value automation opportunities tailored to your organization&#8217;s needs.</p></div>
<div class="paragraph"><p>If you have any questions before tomorrow&#8217;s session, please don&#8217;t hesitate to contact the workshop facilitator. We look forward to working with you to explore the transformative potential of AI agents in your business operations.</p></div></aside></div></section></section></div></div><script src="../assets/reveal.js/dist/reveal.js"></script><script>Array.prototype.slice.call(document.querySelectorAll('.slides section')).forEach(function(slide) {
  if (slide.getAttribute('data-background-color')) return;
  // user needs to explicitly say he wants CSS color to override otherwise we might break custom css or theme (#226)
  if (!(slide.classList.contains('canvas') || slide.classList.contains('background'))) return;
  var bgColor = getComputedStyle(slide).backgroundColor;
  if (bgColor !== 'rgba(0, 0, 0, 0)' && bgColor !== 'transparent') {
    slide.setAttribute('data-background-color', bgColor);
    slide.style.backgroundColor = 'transparent';
  }
});

// More info about config & dependencies:
// - https://github.com/hakimel/reveal.js#configuration
// - https://github.com/hakimel/reveal.js#dependencies
Reveal.initialize({
  // Display presentation control arrows
  controls: true,
  // Help the user learn the controls by providing hints, for example by
  // bouncing the down arrow when they first encounter a vertical slide
  controlsTutorial: true,
  // Determines where controls appear, "edges" or "bottom-right"
  controlsLayout: 'bottom-right',
  // Visibility rule for backwards navigation arrows; "faded", "hidden"
  // or "visible"
  controlsBackArrows: 'faded',
  // Display a presentation progress bar
  progress: true,
  // Display the page number of the current slide
  slideNumber: false,
  // Control which views the slide number displays on
  showSlideNumber: 'all',
  // Add the current slide number to the URL hash so that reloading the
  // page/copying the URL will return you to the same slide
  hash: true,
  // Push each slide change to the browser history. Implies `hash: true`
  history: false,
  // Enable keyboard shortcuts for navigation
  keyboard: true,
  // Enable the slide overview mode
  overview: true,
  // Disables the default reveal.js slide layout so that you can use custom CSS layout
  disableLayout: false,
  // Vertical centering of slides
  center: true,
  // Enables touch navigation on devices with touch input
  touch: true,
  // Loop the presentation
  loop: false,
  // Change the presentation direction to be RTL
  rtl: false,
  // See https://github.com/hakimel/reveal.js/#navigation-mode
  navigationMode: 'default',
  // Randomizes the order of slides each time the presentation loads
  shuffle: false,
  // Turns fragments on and off globally
  fragments: true,
  // Flags whether to include the current fragment in the URL,
  // so that reloading brings you to the same fragment position
  fragmentInURL: false,
  // Flags if the presentation is running in an embedded mode,
  // i.e. contained within a limited portion of the screen
  embedded: false,
  // Flags if we should show a help overlay when the questionmark
  // key is pressed
  help: true,
  // Flags if speaker notes should be visible to all viewers
  showNotes: false,
  // Global override for autolaying embedded media (video/audio/iframe)
  // - null: Media will only autoplay if data-autoplay is present
  // - true: All media will autoplay, regardless of individual setting
  // - false: No media will autoplay, regardless of individual setting
  autoPlayMedia: null,
  // Global override for preloading lazy-loaded iframes
  // - null: Iframes with data-src AND data-preload will be loaded when within
  //   the viewDistance, iframes with only data-src will be loaded when visible
  // - true: All iframes with data-src will be loaded when within the viewDistance
  // - false: All iframes with data-src will be loaded only when visible
  preloadIframes: null,
  // Number of milliseconds between automatically proceeding to the
  // next slide, disabled when set to 0, this value can be overwritten
  // by using a data-autoslide attribute on your slides
  autoSlide: 0,
  // Stop auto-sliding after user input
  autoSlideStoppable: true,
  // Use this method for navigation when auto-sliding
  autoSlideMethod: Reveal.navigateNext,
  // Specify the average time in seconds that you think you will spend
  // presenting each slide. This is used to show a pacing timer in the
  // speaker view
  defaultTiming: 120,
  // Specify the total time in seconds that is available to
  // present.  If this is set to a nonzero value, the pacing
  // timer will work out the time available for each slide,
  // instead of using the defaultTiming value
  totalTime: 0,
  // Specify the minimum amount of time you want to allot to
  // each slide, if using the totalTime calculation method.  If
  // the automated time allocation causes slide pacing to fall
  // below this threshold, then you will see an alert in the
  // speaker notes window
  minimumTimePerSlide: 0,
  // Enable slide navigation via mouse wheel
  mouseWheel: false,
  // Hide cursor if inactive
  hideInactiveCursor: true,
  // Time before the cursor is hidden (in ms)
  hideCursorTime: 5000,
  // Hides the address bar on mobile devices
  hideAddressBar: true,
  // Opens links in an iframe preview overlay
  // Add `data-preview-link` and `data-preview-link="false"` to customise each link
  // individually
  previewLinks: false,
  // Transition style (e.g., none, fade, slide, convex, concave, zoom)
  transition: 'slide',
  // Transition speed (e.g., default, fast, slow)
  transitionSpeed: 'default',
  // Transition style for full page slide backgrounds (e.g., none, fade, slide, convex, concave, zoom)
  backgroundTransition: 'fade',
  // Number of slides away from the current that are visible
  viewDistance: 3,
  // Number of slides away from the current that are visible on mobile
  // devices. It is advisable to set this to a lower number than
  // viewDistance in order to save resources.
  mobileViewDistance: 3,
  // Parallax background image (e.g., "'https://s3.amazonaws.com/hakim-static/reveal-js/reveal-parallax-1.jpg'")
  parallaxBackgroundImage: '',
  // Parallax background size in CSS syntax (e.g., "2100px 900px")
  parallaxBackgroundSize: '',
  // Number of pixels to move the parallax background per slide
  // - Calculated automatically unless specified
  // - Set to 0 to disable movement along an axis
  parallaxBackgroundHorizontal: null,
  parallaxBackgroundVertical: null,
  // The display mode that will be used to show slides
  display: 'block',

  // The "normal" size of the presentation, aspect ratio will be preserved
  // when the presentation is scaled to fit different resolutions. Can be
  // specified using percentage units.
  width: 960,
  height: 700,

  // Factor of the display size that should remain empty around the content
  margin: 0.04,

  // Bounds for smallest/largest possible scale to apply to content
  minScale: 0.2,
  maxScale: 2,

  // PDF Export Options
  // Put each fragment on a separate page
  pdfSeparateFragments: true,
  // For slides that do not fit on a page, max number of pages
  pdfMaxPagesPerSlide: 1,

  // Optional libraries used to extend on reveal.js
  dependencies: [
      { src: '../assets/reveal.js/plugin/zoom/zoom.js', async: true, callback: function () { Reveal.registerPlugin(RevealZoom) } },
      { src: '../assets/reveal.js/plugin/notes/notes.js', async: true, callback: function () { Reveal.registerPlugin(RevealNotes) } }
  ],
});</script><script>var dom = {};
dom.slides = document.querySelector('.reveal .slides');

function getRemainingHeight(element, slideElement, height) {
  height = height || 0;
  if (element) {
    var newHeight, oldHeight = element.style.height;
    // Change the .stretch element height to 0 in order find the height of all
    // the other elements
    element.style.height = '0px';
    // In Overview mode, the parent (.slide) height is set of 700px.
    // Restore it temporarily to its natural height.
    slideElement.style.height = 'auto';
    newHeight = height - slideElement.offsetHeight;
    // Restore the old height, just in case
    element.style.height = oldHeight + 'px';
    // Clear the parent (.slide) height. .removeProperty works in IE9+
    slideElement.style.removeProperty('height');
    return newHeight;
  }
  return height;
}

function layoutSlideContents(width, height) {
  // Handle sizing of elements with the 'stretch' class
  toArray(dom.slides.querySelectorAll('section .stretch')).forEach(function (element) {
    // Determine how much vertical space we can use
    var limit = 5; // hard limit
    var parent = element.parentNode;
    while (parent.nodeName !== 'SECTION' && limit > 0) {
      parent = parent.parentNode;
      limit--;
    }
    if (limit === 0) {
      // unable to find parent, aborting!
      return;
    }
    var remainingHeight = getRemainingHeight(element, parent, height);
    // Consider the aspect ratio of media elements
    if (/(img|video)/gi.test(element.nodeName)) {
      var nw = element.naturalWidth || element.videoWidth, nh = element.naturalHeight || element.videoHeight;
      var es = Math.min(width / nw, remainingHeight / nh);
      element.style.width = (nw * es) + 'px';
      element.style.height = (nh * es) + 'px';
    } else {
      element.style.width = width + 'px';
      element.style.height = remainingHeight + 'px';
    }
  });
}

function toArray(o) {
  return Array.prototype.slice.call(o);
}

Reveal.addEventListener('slidechanged', function () {
  layoutSlideContents(960, 700)
});
Reveal.addEventListener('ready', function () {
  layoutSlideContents(960, 700)
});
Reveal.addEventListener('resize', function () {
  layoutSlideContents(960, 700)
});</script><link rel="stylesheet" href="../assets/theme/github.css"/>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.7.3/highlight.min.js"></script>

<script>

/* highlightjs-line-numbers.js 2.6.0 | (C) 2018 Yauheni Pakala | MIT License | github.com/wcoder/highlightjs-line-numbers.js */
/* Edited by Hakim for reveal.js; removed async timeout */
!function(n,e){"use strict";function t(){var n=e.createElement("style");n.type="text/css",n.innerHTML=g(".{0}{border-collapse:collapse}.{0} td{padding:0}.{1}:before{content:attr({2})}",[v,L,b]),e.getElementsByTagName("head")[0].appendChild(n)}function r(t){"interactive"===e.readyState||"complete"===e.readyState?i(t):n.addEventListener("DOMContentLoaded",function(){i(t)})}function i(t){try{var r=e.querySelectorAll("code.hljs,code.nohighlight");for(var i in r)r.hasOwnProperty(i)&&l(r[i],t)}catch(o){n.console.error("LineNumbers error: ",o)}}function l(n,e){"object"==typeof n&&f(function(){n.innerHTML=s(n,e)})}function o(n,e){if("string"==typeof n){var t=document.createElement("code");return t.innerHTML=n,s(t,e)}}function s(n,e){e=e||{singleLine:!1};var t=e.singleLine?0:1;return c(n),a(n.innerHTML,t)}function a(n,e){var t=u(n);if(""===t[t.length-1].trim()&&t.pop(),t.length>e){for(var r="",i=0,l=t.length;i<l;i++)r+=g('<tr><td class="{0}"><div class="{1} {2}" {3}="{5}"></div></td><td class="{4}"><div class="{1}">{6}</div></td></tr>',[j,m,L,b,p,i+1,t[i].length>0?t[i]:" "]);return g('<table class="{0}">{1}</table>',[v,r])}return n}function c(n){var e=n.childNodes;for(var t in e)if(e.hasOwnProperty(t)){var r=e[t];h(r.textContent)>0&&(r.childNodes.length>0?c(r):d(r.parentNode))}}function d(n){var e=n.className;if(/hljs-/.test(e)){for(var t=u(n.innerHTML),r=0,i="";r<t.length;r++){var l=t[r].length>0?t[r]:" ";i+=g('<span class="{0}">{1}</span>\n',[e,l])}n.innerHTML=i.trim()}}function u(n){return 0===n.length?[]:n.split(y)}function h(n){return(n.trim().match(y)||[]).length}function f(e){e()}function g(n,e){return n.replace(/{(\d+)}/g,function(n,t){return e[t]?e[t]:n})}var v="hljs-ln",m="hljs-ln-line",p="hljs-ln-code",j="hljs-ln-numbers",L="hljs-ln-n",b="data-line-number",y=/\r\n|\r|\n/g;n.hljs?(n.hljs.initLineNumbersOnLoad=r,n.hljs.lineNumbersBlock=l,n.hljs.lineNumbersValue=o,t()):n.console.error("highlight.js not detected!")}(window,document);

/**
 * This reveal.js plugin is wrapper around the highlight.js
 * syntax highlighting library.
 */
(function( root, factory ) {
  if (typeof define === 'function' && define.amd) {
    root.RevealHighlight = factory();
  } else if( typeof exports === 'object' ) {
    module.exports = factory();
  } else {
    // Browser globals (root is window)
    root.RevealHighlight = factory();
  }
}( this, function() {

  // Function to perform a better "data-trim" on code snippets
  // Will slice an indentation amount on each line of the snippet (amount based on the line having the lowest indentation length)
  function betterTrim(snippetEl) {
    // Helper functions
    function trimLeft(val) {
      // Adapted from https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/String/Trim#Polyfill
      return val.replace(/^[\s\uFEFF\xA0]+/g, '');
    }
    function trimLineBreaks(input) {
      var lines = input.split('\n');

      // Trim line-breaks from the beginning
      for (var i = 0; i < lines.length; i++) {
        if (lines[i].trim() === '') {
          lines.splice(i--, 1);
        } else break;
      }

      // Trim line-breaks from the end
      for (var i = lines.length-1; i >= 0; i--) {
        if (lines[i].trim() === '') {
          lines.splice(i, 1);
        } else break;
      }

      return lines.join('\n');
    }

    // Main function for betterTrim()
    return (function(snippetEl) {
      var content = trimLineBreaks(snippetEl.innerHTML);
      var lines = content.split('\n');
      // Calculate the minimum amount to remove on each line start of the snippet (can be 0)
      var pad = lines.reduce(function(acc, line) {
        if (line.length > 0 && trimLeft(line).length > 0 && acc > line.length - trimLeft(line).length) {
          return line.length - trimLeft(line).length;
        }
        return acc;
      }, Number.POSITIVE_INFINITY);
      // Slice each line with this amount
      return lines.map(function(line, index) {
        return line.slice(pad);
      })
        .join('\n');
    })(snippetEl);
  }

  var RevealHighlight = {

    HIGHLIGHT_STEP_DELIMITER: '|',
    HIGHLIGHT_LINE_DELIMITER: ',',
    HIGHLIGHT_LINE_RANGE_DELIMITER: '-',

    init: function( reveal ) {

      // Read the plugin config options and provide fallbacks
      var config = Reveal.getConfig().highlight || {};
      config.highlightOnLoad = typeof config.highlightOnLoad === 'boolean' ? config.highlightOnLoad : true;
      config.escapeHTML = typeof config.escapeHTML === 'boolean' ? config.escapeHTML : true;

      [].slice.call( reveal.getRevealElement().querySelectorAll( 'pre code' ) ).forEach( function( block ) {

        block.parentNode.className = 'code-wrapper';

        // Code can optionally be wrapped in script template to avoid
        // HTML being parsed by the browser (i.e. when you need to
        // include <, > or & in your code).
        let substitute = block.querySelector( 'script[type="text/template"]' );
        if( substitute ) {
          // textContent handles the HTML entity escapes for us
          block.textContent = substitute.innerHTML;
        }

        // Trim whitespace if the "data-trim" attribute is present
        if( block.hasAttribute( 'data-trim' ) && typeof block.innerHTML.trim === 'function' ) {
          block.innerHTML = betterTrim( block );
        }

        // Escape HTML tags unless the "data-noescape" attrbute is present
        if( config.escapeHTML && !block.hasAttribute( 'data-noescape' )) {
          block.innerHTML = block.innerHTML.replace( /</g,"&lt;").replace(/>/g, '&gt;' );
        }

        // Re-highlight when focus is lost (for contenteditable code)
        block.addEventListener( 'focusout', function( event ) {
          hljs.highlightElement( event.currentTarget );
        }, false );

        if( config.highlightOnLoad ) {
          RevealHighlight.highlightBlock( block );
        }
      } );

      // If we're printing to PDF, scroll the code highlights of
      // all blocks in the deck into view at once
      reveal.on( 'pdf-ready', function() {
        [].slice.call( reveal.getRevealElement().querySelectorAll( 'pre code[data-line-numbers].current-fragment' ) ).forEach( function( block ) {
          RevealHighlight.scrollHighlightedLineIntoView( block, {}, true );
        } );
      } );
    },

    /**
     * Highlights a code block. If the <code> node has the
     * 'data-line-numbers' attribute we also generate slide
     * numbers.
     *
     * If the block contains multiple line highlight steps,
     * we clone the block and create a fragment for each step.
     */
    highlightBlock: function( block ) {

      hljs.highlightElement( block );

      // Don't generate line numbers for empty code blocks
      if( block.innerHTML.trim().length === 0 ) return;

      if( block.hasAttribute( 'data-line-numbers' ) ) {
        hljs.lineNumbersBlock( block, { singleLine: true } );

        var scrollState = { currentBlock: block };

        // If there is at least one highlight step, generate
        // fragments
        var highlightSteps = RevealHighlight.deserializeHighlightSteps( block.getAttribute( 'data-line-numbers' ) );
        if( highlightSteps.length > 1 ) {

          // If the original code block has a fragment-index,
          // each clone should follow in an incremental sequence
          var fragmentIndex = parseInt( block.getAttribute( 'data-fragment-index' ), 10 );

          if( typeof fragmentIndex !== 'number' || isNaN( fragmentIndex ) ) {
            fragmentIndex = null;
          }

          // Generate fragments for all steps except the original block
          highlightSteps.slice(1).forEach( function( highlight ) {

            var fragmentBlock = block.cloneNode( true );
            fragmentBlock.setAttribute( 'data-line-numbers', RevealHighlight.serializeHighlightSteps( [ highlight ] ) );
            fragmentBlock.classList.add( 'fragment' );
            block.parentNode.appendChild( fragmentBlock );
            RevealHighlight.highlightLines( fragmentBlock );

            if( typeof fragmentIndex === 'number' ) {
              fragmentBlock.setAttribute( 'data-fragment-index', fragmentIndex );
              fragmentIndex += 1;
            }
            else {
              fragmentBlock.removeAttribute( 'data-fragment-index' );
            }

            // Scroll highlights into view as we step through them
            fragmentBlock.addEventListener( 'visible', RevealHighlight.scrollHighlightedLineIntoView.bind( Plugin, fragmentBlock, scrollState ) );
            fragmentBlock.addEventListener( 'hidden', RevealHighlight.scrollHighlightedLineIntoView.bind( Plugin, fragmentBlock.previousSibling, scrollState ) );

          } );

          block.removeAttribute( 'data-fragment-index' )
          block.setAttribute( 'data-line-numbers', RevealHighlight.serializeHighlightSteps( [ highlightSteps[0] ] ) );

        }

        // Scroll the first highlight into view when the slide
        // becomes visible. Note supported in IE11 since it lacks
        // support for Element.closest.
        var slide = typeof block.closest === 'function' ? block.closest( 'section:not(.stack)' ) : null;
        if( slide ) {
          var scrollFirstHighlightIntoView = function() {
            RevealHighlight.scrollHighlightedLineIntoView( block, scrollState, true );
            slide.removeEventListener( 'visible', scrollFirstHighlightIntoView );
          }
          slide.addEventListener( 'visible', scrollFirstHighlightIntoView );
        }

        RevealHighlight.highlightLines( block );

      }

    },

    /**
     * Animates scrolling to the first highlighted line
     * in the given code block.
     */
    scrollHighlightedLineIntoView: function( block, scrollState, skipAnimation ) {

      cancelAnimationFrame( scrollState.animationFrameID );

      // Match the scroll position of the currently visible
      // code block
      if( scrollState.currentBlock ) {
        block.scrollTop = scrollState.currentBlock.scrollTop;
      }

      // Remember the current code block so that we can match
      // its scroll position when showing/hiding fragments
      scrollState.currentBlock = block;

      var highlightBounds = RevealHighlight.getHighlightedLineBounds( block )
      var viewportHeight = block.offsetHeight;

      // Subtract padding from the viewport height
      var blockStyles = getComputedStyle( block );
      viewportHeight -= parseInt( blockStyles.paddingTop ) + parseInt( blockStyles.paddingBottom );

      // Scroll position which centers all highlights
      var startTop = block.scrollTop;
      var targetTop = highlightBounds.top + ( Math.min( highlightBounds.bottom - highlightBounds.top, viewportHeight ) - viewportHeight ) / 2;

      // Account for offsets in position applied to the
      // <table> that holds our lines of code
      var lineTable = block.querySelector( '.hljs-ln' );
      if( lineTable ) targetTop += lineTable.offsetTop - parseInt( blockStyles.paddingTop );

      // Make sure the scroll target is within bounds
      targetTop = Math.max( Math.min( targetTop, block.scrollHeight - viewportHeight ), 0 );

      if( skipAnimation === true || startTop === targetTop ) {
        block.scrollTop = targetTop;
      }
      else {

        // Don't attempt to scroll if there is no overflow
        if( block.scrollHeight <= viewportHeight ) return;

        var time = 0;
        var animate = function() {
          time = Math.min( time + 0.02, 1 );

          // Update our eased scroll position
          block.scrollTop = startTop + ( targetTop - startTop ) * RevealHighlight.easeInOutQuart( time );

          // Keep animating unless we've reached the end
          if( time < 1 ) {
            scrollState.animationFrameID = requestAnimationFrame( animate );
          }
        };

        animate();

      }

    },

    /**
     * The easing function used when scrolling.
     */
    easeInOutQuart: function( t ) {

      // easeInOutQuart
      return t<.5 ? 8*t*t*t*t : 1-8*(--t)*t*t*t;

    },

    getHighlightedLineBounds: function( block ) {

      var highlightedLines = block.querySelectorAll( '.highlight-line' );
      if( highlightedLines.length === 0 ) {
        return { top: 0, bottom: 0 };
      }
      else {
        var firstHighlight = highlightedLines[0];
        var lastHighlight = highlightedLines[ highlightedLines.length -1 ];

        return {
          top: firstHighlight.offsetTop,
          bottom: lastHighlight.offsetTop + lastHighlight.offsetHeight
        }
      }

    },

    /**
     * Visually emphasize specific lines within a code block.
     * This only works on blocks with line numbering turned on.
     *
     * @param {HTMLElement} block a <code> block
     * @param {String} [linesToHighlight] The lines that should be
     * highlighted in this format:
     * "1" 		= highlights line 1
     * "2,5"	= highlights lines 2 & 5
     * "2,5-7"	= highlights lines 2, 5, 6 & 7
     */
    highlightLines: function( block, linesToHighlight ) {

      var highlightSteps = RevealHighlight.deserializeHighlightSteps( linesToHighlight || block.getAttribute( 'data-line-numbers' ) );

      if( highlightSteps.length ) {

        highlightSteps[0].forEach( function( highlight ) {

          var elementsToHighlight = [];

          // Highlight a range
          if( typeof highlight.end === 'number' ) {
            elementsToHighlight = [].slice.call( block.querySelectorAll( 'table tr:nth-child(n+'+highlight.start+'):nth-child(-n+'+highlight.end+')' ) );
          }
          // Highlight a single line
          else if( typeof highlight.start === 'number' ) {
            elementsToHighlight = [].slice.call( block.querySelectorAll( 'table tr:nth-child('+highlight.start+')' ) );
          }

          if( elementsToHighlight.length ) {
            elementsToHighlight.forEach( function( lineElement ) {
              lineElement.classList.add( 'highlight-line' );
            } );

            block.classList.add( 'has-highlights' );
          }

        } );

      }

    },

    /**
     * Parses and formats a user-defined string of line
     * numbers to highlight.
     *
     * @example
     * RevealHighlight.deserializeHighlightSteps( '1,2|3,5-10' )
     * // [
     * //   [ { start: 1 }, { start: 2 } ],
     * //   [ { start: 3 }, { start: 5, end: 10 } ]
     * // ]
     */
    deserializeHighlightSteps: function( highlightSteps ) {

      // Remove whitespace
      highlightSteps = highlightSteps.replace( /\s/g, '' );

      // Divide up our line number groups
      highlightSteps = highlightSteps.split( RevealHighlight.HIGHLIGHT_STEP_DELIMITER );

      return highlightSteps.map( function( highlights ) {

        return highlights.split( RevealHighlight.HIGHLIGHT_LINE_DELIMITER ).map( function( highlight ) {

          // Parse valid line numbers
          if( /^[\d-]+$/.test( highlight ) ) {

            highlight = highlight.split( RevealHighlight.HIGHLIGHT_LINE_RANGE_DELIMITER );

            var lineStart = parseInt( highlight[0], 10 ),
              lineEnd = parseInt( highlight[1], 10 );

            if( isNaN( lineEnd ) ) {
              return {
                start: lineStart
              };
            }
            else {
              return {
                start: lineStart,
                end: lineEnd
              };
            }

          }
          // If no line numbers are provided, no code will be highlighted
          else {

            return {};

          }

        } );

      } );

    },

    /**
     * Serializes parsed line number data into a string so
     * that we can store it in the DOM.
     */
    serializeHighlightSteps: function( highlightSteps ) {

      return highlightSteps.map( function( highlights ) {

        return highlights.map( function( highlight ) {

          // Line range
          if( typeof highlight.end === 'number' ) {
            return highlight.start + RevealHighlight.HIGHLIGHT_LINE_RANGE_DELIMITER + highlight.end;
          }
          // Single line
          else if( typeof highlight.start === 'number' ) {
            return highlight.start;
          }
          // All lines
          else {
            return '';
          }

        } ).join( RevealHighlight.HIGHLIGHT_LINE_DELIMITER );

      } ).join( RevealHighlight.HIGHLIGHT_STEP_DELIMITER );

    }

  }

  Reveal.registerPlugin( 'highlight', RevealHighlight );

  return RevealHighlight;

}));
        
hljs.configure({
  ignoreUnescapedHTML: true,
});
hljs.highlightAll();
</script></body></html>