== Understanding Large Language Models

[.notes]
--
In this module, we'll develop a deeper understanding of Large Language Models (LLMs) - what they are, how they work at a high level, and the different approaches to their development. This understanding is essential for evaluating their potential applications in your business.

We'll explore the fundamental capabilities of LLMs and how they process and generate language. We'll then examine different types of LLMs, particularly the distinction between probabilistic models like GPT-4o and reasoning-based models like Claude 3 Opus or GPT-4o with specific prompting techniques.

By understanding these different approaches and their respective strengths and limitations, you'll be better equipped to determine which type of LLM might be most appropriate for different business applications. This knowledge will directly inform your ability to identify and evaluate AI opportunities in your organization.
--

=== What are LLMs? Core Mechanics

* AI systems trained on vast text datasets to understand and generate human language
* Process information by breaking text into tokens (word parts) and analyzing patterns
* Predict likely next words/tokens based on patterns learned during training

[.notes]
--
Large Language Models (LLMs) are a type of artificial intelligence system specifically designed to understand and generate human language. Let's explore their fundamental characteristics:

LLMs are trained on vast text datasets, often comprising hundreds of billions of words from sources like books, articles, websites, code repositories, and other text-based content. This extensive training allows them to learn the patterns, structures, and relationships in human language across diverse topics and domains. The largest models have effectively "read" more text than any human could in multiple lifetimes.

These models process information by breaking text into tokens, which are essentially word parts or complete words. For example, the word "understanding" might be broken into tokens like "under" and "standing." The model analyzes patterns in how these tokens appear in relation to each other across its training data. This tokenization approach allows the model to handle words it hasn't explicitly seen before by recognizing their component parts.

At their core, LLMs predict likely next words or tokens based on the patterns they've learned. When given a prompt or partial text, they calculate probabilities for what might come next based on similar patterns in their training data. This predictive capability is what enables them to generate coherent and contextually appropriate text that continues from any starting point.
--

=== Understanding Tokenization

* Tokens are the basic units LLMs process - can be words, parts of words, or punctuation
* Examples:
  ** "Artificial" → "Art" + "ificial"
  ** "intelligence" → "intel" + "ligence"
  ** "doesn't" → "doesn" + "'t"
* Most models use 1,000-100,000 unique tokens in their vocabulary
* Efficient compression of language into machine-readable units

[.notes]
--
Tokenization is a fundamental process that converts human text into a format that LLMs can process. Understanding how tokenization works helps explain both the capabilities and limitations of these models:

Tokens represent the basic units that LLMs process. Unlike traditional NLP systems that might work with whole words, LLMs break text down into subword units. These tokens can be complete words, parts of words, or even individual characters and punctuation marks. This approach allows the model to handle a virtually unlimited vocabulary by combining token pieces.

The tokenization process follows specific patterns based on the frequency of character combinations in the training data. Common words like "the" or "and" typically get their own tokens, while less common words are split into multiple tokens. For example, "tokenization" might be broken into "token" + "ization" because these parts appear frequently in other words.

Different LLM systems use different tokenization approaches. GPT models use a method called Byte-Pair Encoding (BPE), while some other models use WordPiece or SentencePiece tokenizers. Regardless of the specific method, all modern LLMs use some form of subword tokenization.

The size of a model's token vocabulary typically ranges from about 1,000 to 100,000 unique tokens. This vocabulary represents the building blocks the model uses to understand and generate all text. The specific tokens in this vocabulary are determined during the pre-training process based on the frequency of character patterns in the training data.

Tokenization has important practical implications. When using LLMs, inputs are counted in tokens, not words or characters. This affects usage costs for commercial APIs and context window limitations. As a rule of thumb, one word typically corresponds to about 1.3-1.5 tokens in English, though this varies widely depending on the specific text.

Understanding tokenization helps explain why LLMs sometimes struggle with very rare words, made-up terms, or specialized technical vocabulary. If a word must be broken into many small token pieces, the model may have difficulty maintaining coherence across those pieces during processing.
--

=== Prediction Mechanism: Probability Distribution

* LLMs function as next-token prediction engines
* For input: "The capital of France is..."
* Model calculates probability distribution across entire vocabulary:
  ** "Paris": 92%
  ** "Lyon": 2%
  ** "located": 1%
  ** [thousands of other possibilities with lower probabilities]

[.notes]
--
At their core, LLMs operate through a surprisingly simple mechanism: they predict the next token in a sequence based on all the tokens that came before it. This fundamental prediction capability is what enables all their more complex behaviors:

When an LLM receives input text, it processes this text token by token, building an internal representation of the context. This representation captures patterns, relationships, and semantic meanings from the input.

For each position in the sequence, the model calculates a probability distribution across its entire vocabulary of tokens. This distribution represents the model's prediction of how likely each possible token is to appear next in the sequence. For example, given the prompt "The capital of France is," the model might assign a 92% probability to "Paris," a 2% probability to "Lyon," a 1% probability to "located," and distribute the remaining 5% across thousands of other tokens.

The model then selects a token from this probability distribution. In the simplest case, it selects the highest probability token (a process called "greedy decoding"). However, most implementations use more sophisticated sampling methods that introduce controlled randomness to generate more diverse and interesting outputs.
--

=== Prediction Mechanism: Temperature & Generation

* Temperature setting controls randomness in token selection:
  ** Low temp (0.1-0.5): More predictable, focused outputs
  ** Medium temp (0.6-0.8): Balanced creativity & accuracy
  ** High temp (0.9-1.0+): More creative, diverse outputs
* Each selected token becomes part of context for next prediction
  ** This iterative process continues until completion

[.notes]
--
The "temperature" setting that many LLM interfaces provide controls the randomness in the token selection process. This parameter fundamentally alters how the model generates text:

At low temperatures (typically 0.1-0.5), the model strongly favors high-probability tokens. This results in more predictable, focused, and often more factually accurate outputs. Low temperatures are ideal for tasks requiring precision, such as answering factual questions or generating code.

At medium temperatures (around 0.6-0.8), the model strikes a balance between selecting high-probability tokens and occasionally choosing less likely options. This creates outputs with a good balance of coherence and creativity, making it suitable for many general-purpose applications.

At high temperatures (0.9 and above), the model is much more likely to select lower-probability tokens. This produces more diverse, creative, and sometimes surprising outputs, but with increased risk of incoherence or factual errors. High temperatures work well for creative writing, brainstorming, or generating varied alternatives.

Once a token is selected, it's added to the sequence, and the process repeats. The model now calculates a new probability distribution for the next position, taking into account the newly added token. This iterative process continues until the model generates a stopping token or reaches a predefined length limit.

What's remarkable is that this relatively simple prediction mechanism, when scaled up with billions of parameters and trained on vast datasets, enables the complex capabilities we observe in modern LLMs. The model isn't explicitly programmed to answer questions, write essays, or solve problems—it's simply predicting what tokens are likely to come next in a given context. The emergent behaviors we value arise from this fundamental prediction capability.
--

=== LLM Capabilities and Applications

* LLMs demonstrate capabilities in writing, summarizing, answering questions, and reasoning
* Represent a general-purpose technology with applications across business functions
* All complex behaviors emerge from the simple next-token prediction mechanism

[.notes]
--
Modern LLMs demonstrate remarkable capabilities across a range of language tasks. They can write essays, stories, or business documents; summarize lengthy content; answer questions based on their training data; translate between languages; and even perform reasoning tasks that require multiple steps of logical thinking. These capabilities emerge from their statistical understanding of language patterns rather than explicit programming.

From a business perspective, LLMs represent a general-purpose technology with applications across virtually every function and industry. Unlike previous AI systems that were designed for specific narrow tasks, LLMs can be applied to a wide range of language-related challenges through appropriate prompting or fine-tuning. This flexibility makes them particularly valuable as a business tool.

Understanding LLMs as pattern-recognition systems trained on language data helps explain both their impressive capabilities and their limitations. They don't "understand" text in the human sense but have learned statistical patterns that allow them to mimic understanding in ways that are increasingly useful for business applications.

What makes LLMs particularly remarkable is that all these diverse capabilities—from writing marketing copy to analyzing financial data to generating computer code—emerge from the same fundamental next-token prediction mechanism. The model's ability to perform such varied tasks comes from the patterns it learned during training rather than from task-specific programming. This explains why the same model can switch between different types of tasks simply based on how it's prompted.
--

=== !

[.h4-style]
There are two types of LLMs:
[.h3-style]
Probabilistic
[.h3-style]
Chain-of-Thought Reasoning

=== Probabilistic LLMs

* Trained to predict the next token based on statistical patterns in training data
* Generate text by repeatedly predicting the most likely next word/token
* Process is purely statistical - no explicit rules about grammar, facts, or reasoning
* Each prediction influenced by the entire context provided so far
* Examples: OpenAI's GPT-4o, Anthropic's Claude 3.5, Meta's Llama2

[.notes]
--
Probabilistic LLMs like GPT-4o represent the most common approach to language model development. Let's explore how they work and their business implications:

These models are trained through a process called "next token prediction." During training, the model is shown vast amounts of text and learns to predict what word or token is likely to come next in any given sequence. This training objective is purely statistical - the model learns patterns of word co-occurrence across billions of examples without explicit rules about grammar, facts, or reasoning.

When generating text, probabilistic LLMs work by repeatedly predicting the most likely next word or token based on what they've already generated. Each prediction is influenced by the entire context provided so far. The model calculates probability distributions across its entire vocabulary (often 100,000+ tokens) and selects from these possibilities. This process continues word by word until the response is complete.
--

=== Probabilistic: Strengths & Limitations

* Strengths:
  ** Remarkably fluent, natural-sounding writing
  ** Broad knowledge across diverse domains
  ** Creative content generation capabilities
* Limitations:
  ** May "hallucinate" facts that sound plausible but are incorrect
  ** Can struggle with complex multi-step reasoning
  ** Limited by training data cutoff and potential biases

[.notes]
--
The strengths of probabilistic LLMs include remarkably fluent writing that mimics human language patterns, broad knowledge across diverse domains absorbed from their training data, and creative capabilities in generating novel content like stories, marketing copy, or business ideas. They excel at tasks requiring language fluency and general knowledge.

However, these models have important limitations. They may "hallucinate" facts that sound plausible but are incorrect, as they're optimizing for plausible-sounding text rather than factual accuracy. They can struggle with complex multi-step reasoning, particularly for problems requiring precise logical or mathematical thinking. They're also limited by their training data - they don't have real-time information beyond their training cutoff and may reflect biases present in that data.

Understanding the probabilistic nature of these models helps explain both their impressive capabilities and their limitations. They don't "know" facts in the human sense but have learned statistical patterns that allow them to generate text that often contains accurate information. This distinction is important when evaluating their potential applications in business contexts where factual accuracy or reliable reasoning may be critical.
--

=== Probabilistic: Business Applications

* Content creation: marketing materials, reports, communications
* Document summarization and information extraction
* Creative ideation and brainstorming
* Customer support automation and chatbots
* Knowledge management and information retrieval
* Draft generation with human review and refinement

[.notes]
--
From a business perspective, probabilistic LLMs are particularly valuable for a wide range of applications:

Content creation is one of the most common use cases, with LLMs helping to generate marketing materials, reports, emails, and other business communications. The models can produce drafts quickly that humans can then review and refine.

Document summarization is another powerful application, allowing these models to condense lengthy reports, articles, or transcripts into concise summaries that capture key points. This can dramatically improve information processing efficiency.

For creative tasks, LLMs excel at ideation and brainstorming, generating diverse perspectives and approaches that can spark innovation. They can suggest multiple angles on a problem or help develop creative concepts for marketing campaigns.

Customer support automation has been revolutionized by these models, which can handle a wide range of customer inquiries with natural-sounding responses. They can be deployed as chatbots or used to assist human agents with response suggestions.

Knowledge management applications leverage LLMs' ability to process and retrieve information from large document collections, making organizational knowledge more accessible and useful.

The most effective business implementations typically combine LLM capabilities with human oversight, using the models to generate initial drafts or suggestions that humans then review, edit, and approve. This human-in-the-loop approach mitigates the risk of hallucinations or errors while still capturing the efficiency benefits.
--

=== Chain-of-Thought (CoT) Reasoning LLMs

* Specifically trained or prompted to show explicit reasoning steps
* Process complex problems by breaking them into logical sequences
* Examples: OpenAI's o1/o3, DeepSeek-R1
* Example approach for a math problem:
  ** Identify relevant variables and formulas
  ** Work through calculations step-by-step
  ** Verify results before providing final answer

[.notes]
--
Chain-of-Thought (CoT) reasoning represents an important advancement in LLM capabilities, particularly evident in models like OpenAI's o1 and o3 or when using specific prompting techniques with models like GPT-4:

These models are either specifically trained or prompted to show explicit reasoning steps rather than jumping directly to conclusions. When faced with a complex problem, they break it down into a logical sequence of steps, working through the problem methodically much like a human would. This approach dramatically improves performance on tasks requiring multi-step reasoning.

The key innovation in CoT models is their ability to process complex problems by breaking them into manageable components. For example, when solving a math problem, the model might first identify the relevant variables, then determine the appropriate formula, perform the calculation step by step, and finally verify the result. This step-by-step approach significantly reduces errors compared to attempting to solve problems in a single step.

Chain-of-thought reasoning can be elicited in two primary ways: through specific model training that rewards step-by-step reasoning, or through prompting techniques that explicitly instruct the model to "think step by step" before answering. Both approaches have proven effective at improving performance on complex reasoning tasks.
--

=== CoT Reasoning: Strengths & Limitations

* Strengths:
  ** Superior mathematical and logical reasoning
  ** Transparent decision-making process
  ** Reduced error rates on complex problems
  ** Self-correction capabilities
* Limitations:
  ** Higher computational requirements
  ** Potentially slower response times
  ** Still probabilistic at core - can make reasoning errors

[.notes]
--
The strengths of CoT models include superior performance on mathematical reasoning tasks, logical problem-solving that requires multiple steps, and transparent decision-making where the reasoning process is visible and can be verified. This transparency is particularly valuable in business contexts where understanding how a conclusion was reached may be as important as the conclusion itself.

A key advantage of chain-of-thought reasoning is the ability to self-correct. By working through problems step-by-step, these models can often identify errors in their own reasoning and revise their approach before arriving at a final answer. This significantly reduces error rates compared to models that attempt to solve problems in a single step.

However, these models have limitations. They typically require more computational resources, which can result in higher costs and potentially slower responses compared to standard LLMs. They're also still fundamentally probabilistic systems at their core, meaning they can make reasoning errors despite their step-by-step approach. Their performance depends significantly on how problems are presented to them.

A key development in this area is the concept of "test-time compute" as a scaling law. Research has shown that allowing models more computation time to think through problems step by step can significantly improve performance, even without increasing model size. This insight suggests that future models may become increasingly capable of complex reasoning tasks simply by allocating more computational resources at inference time.
--

=== CoT Reasoning: Business Applications

* Financial analysis and modeling
* Complex decision support with transparent rationale
* Process optimization and troubleshooting
* Risk assessment and scenario planning
* Educational applications and training
* Regulatory compliance with documented reasoning

[.notes]
--
From a business perspective, CoT models are particularly valuable for applications requiring complex reasoning and transparency:

Financial analysis and modeling benefit greatly from chain-of-thought reasoning, as these models can work through complex calculations while showing their work. This is especially valuable for investment decisions, financial forecasting, and budget planning where stakeholders need to understand the reasoning behind recommendations.

For complex decision support, these models can evaluate multiple factors, weigh trade-offs, and provide recommendations with clear rationales. The transparency of their reasoning process builds trust and allows decision-makers to evaluate the quality of the analysis.

Process optimization and troubleshooting are enhanced by the models' ability to systematically analyze workflows, identify bottlenecks, and suggest improvements with detailed explanations. This applies to manufacturing processes, supply chain optimization, and service delivery improvements.

Risk assessment and scenario planning benefit from the models' ability to methodically work through different scenarios and their implications, helping organizations prepare for various contingencies with well-reasoned strategies.

Educational applications leverage these models' ability to explain complex concepts step-by-step, making them valuable tools for training, knowledge transfer, and skill development within organizations.

Regulatory compliance is another area where documented reasoning is particularly valuable. When decisions need to be justified to regulators or auditors, having a clear record of the reasoning process provides necessary transparency and accountability.

Understanding the capabilities and limitations of CoT reasoning is crucial for identifying business problems where this approach might add significant value compared to standard probabilistic LLMs.
--

=== Comparing LLM Approaches

* Probabilistic models excel at fluent generation and broad knowledge tasks
* CoT Reasoning models perform better on complex problem-solving requiring logical steps
* Cost considerations: CoT Reasoning approaches may require more computational resources
* Response time: Step-by-step CoT reasoning typically takes longer than direct generation
* Hybrid approaches often provide the best results for complex business applications

[.notes]
--
Understanding the relative strengths and appropriate applications of different LLM approaches is crucial for effective business implementation:

Probabilistic models excel at tasks requiring fluent language generation and broad knowledge. They're particularly effective for content creation, summarization, creative writing, general question answering, and conversational interfaces. Their strength lies in their ability to generate natural-sounding text across a wide range of topics based on patterns learned from their training data. For many business applications where approximate answers or creative content are sufficient, probabilistic models offer an excellent balance of performance and efficiency.

Reasoning models perform significantly better on tasks requiring complex problem-solving with logical steps. They're particularly valuable for mathematical calculations, logical deductions, step-by-step analyses, and situations where the reasoning process itself needs to be transparent. Their explicit reasoning approach reduces errors on complex tasks and provides visibility into how conclusions are reached. For business applications where accuracy and verifiability are critical, reasoning-based approaches often justify their additional resource requirements.

Cost considerations play an important role in choosing between approaches. Reasoning-based methods typically require more computational resources, which translates to higher costs in cloud-based API implementations. The explicit generation of intermediate reasoning steps means more tokens are generated, directly affecting usage-based pricing models. Organizations need to weigh these additional costs against the value of improved accuracy and transparency for specific use cases.

Response time is another important factor. Step-by-step reasoning naturally takes longer than direct generation, as the model works through multiple intermediate steps before reaching a conclusion. For applications where immediate responses are critical, this additional latency may be problematic. However, for complex analytical tasks where accuracy is paramount, the additional time is often a worthwhile tradeoff.

In practice, hybrid approaches often provide the best results for complex business applications. Many implementations use probabilistic models for initial content generation or simple queries, then switch to reasoning approaches for complex problems requiring verification or step-by-step analysis. Some systems also implement verification steps where outputs from probabilistic generation are checked using reasoning approaches before being presented to users.

The field continues to evolve rapidly, with models increasingly incorporating reasoning capabilities as a standard feature rather than a separate approach. Understanding the appropriate application of different techniques allows organizations to optimize their AI implementations for specific business needs, balancing performance, cost, speed, and accuracy.
--

